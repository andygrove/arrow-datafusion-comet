== Physical Plan ==
TakeOrderedAndProject (92)
+- * BroadcastHashJoin Inner BuildRight (91)
   :- * Filter (74)
   :  +- * HashAggregate (73)
   :     +- Exchange (72)
   :        +- * HashAggregate (71)
   :           +- * Project (70)
   :              +- * BroadcastHashJoin Inner BuildRight (69)
   :                 :- * Project (67)
   :                 :  +- * BroadcastHashJoin Inner BuildRight (66)
   :                 :     :- * BroadcastHashJoin LeftSemi BuildRight (59)
   :                 :     :  :- * ColumnarToRow (3)
   :                 :     :  :  +- CometFilter (2)
   :                 :     :  :     +- CometScan parquet spark_catalog.default.store_sales (1)
   :                 :     :  +- BroadcastExchange (58)
   :                 :     :     +- * Project (57)
   :                 :     :        +- * BroadcastHashJoin Inner BuildRight (56)
   :                 :     :           :- * ColumnarToRow (6)
   :                 :     :           :  +- CometFilter (5)
   :                 :     :           :     +- CometScan parquet spark_catalog.default.item (4)
   :                 :     :           +- BroadcastExchange (55)
   :                 :     :              +- * BroadcastHashJoin LeftSemi BuildRight (54)
   :                 :     :                 :- * HashAggregate (38)
   :                 :     :                 :  +- Exchange (37)
   :                 :     :                 :     +- * ColumnarToRow (36)
   :                 :     :                 :        +- CometHashAggregate (35)
   :                 :     :                 :           +- CometProject (34)
   :                 :     :                 :              +- CometBroadcastHashJoin (33)
   :                 :     :                 :                 :- CometProject (28)
   :                 :     :                 :                 :  +- CometBroadcastHashJoin (27)
   :                 :     :                 :                 :     :- CometFilter (8)
   :                 :     :                 :                 :     :  +- CometScan parquet spark_catalog.default.store_sales (7)
   :                 :     :                 :                 :     +- CometBroadcastExchange (26)
   :                 :     :                 :                 :        +- CometBroadcastHashJoin (25)
   :                 :     :                 :                 :           :- CometFilter (10)
   :                 :     :                 :                 :           :  +- CometScan parquet spark_catalog.default.item (9)
   :                 :     :                 :                 :           +- CometBroadcastExchange (24)
   :                 :     :                 :                 :              +- CometProject (23)
   :                 :     :                 :                 :                 +- CometBroadcastHashJoin (22)
   :                 :     :                 :                 :                    :- CometProject (17)
   :                 :     :                 :                 :                    :  +- CometBroadcastHashJoin (16)
   :                 :     :                 :                 :                    :     :- CometFilter (12)
   :                 :     :                 :                 :                    :     :  +- CometScan parquet spark_catalog.default.catalog_sales (11)
   :                 :     :                 :                 :                    :     +- CometBroadcastExchange (15)
   :                 :     :                 :                 :                    :        +- CometFilter (14)
   :                 :     :                 :                 :                    :           +- CometScan parquet spark_catalog.default.item (13)
   :                 :     :                 :                 :                    +- CometBroadcastExchange (21)
   :                 :     :                 :                 :                       +- CometProject (20)
   :                 :     :                 :                 :                          +- CometFilter (19)
   :                 :     :                 :                 :                             +- CometScan parquet spark_catalog.default.date_dim (18)
   :                 :     :                 :                 +- CometBroadcastExchange (32)
   :                 :     :                 :                    +- CometProject (31)
   :                 :     :                 :                       +- CometFilter (30)
   :                 :     :                 :                          +- CometScan parquet spark_catalog.default.date_dim (29)
   :                 :     :                 +- BroadcastExchange (53)
   :                 :     :                    +- * ColumnarToRow (52)
   :                 :     :                       +- CometProject (51)
   :                 :     :                          +- CometBroadcastHashJoin (50)
   :                 :     :                             :- CometProject (45)
   :                 :     :                             :  +- CometBroadcastHashJoin (44)
   :                 :     :                             :     :- CometFilter (40)
   :                 :     :                             :     :  +- CometScan parquet spark_catalog.default.web_sales (39)
   :                 :     :                             :     +- CometBroadcastExchange (43)
   :                 :     :                             :        +- CometFilter (42)
   :                 :     :                             :           +- CometScan parquet spark_catalog.default.item (41)
   :                 :     :                             +- CometBroadcastExchange (49)
   :                 :     :                                +- CometProject (48)
   :                 :     :                                   +- CometFilter (47)
   :                 :     :                                      +- CometScan parquet spark_catalog.default.date_dim (46)
   :                 :     +- BroadcastExchange (65)
   :                 :        +- * BroadcastHashJoin LeftSemi BuildRight (64)
   :                 :           :- * ColumnarToRow (62)
   :                 :           :  +- CometFilter (61)
   :                 :           :     +- CometScan parquet spark_catalog.default.item (60)
   :                 :           +- ReusedExchange (63)
   :                 +- ReusedExchange (68)
   +- BroadcastExchange (90)
      +- * Filter (89)
         +- * HashAggregate (88)
            +- Exchange (87)
               +- * HashAggregate (86)
                  +- * Project (85)
                     +- * BroadcastHashJoin Inner BuildRight (84)
                        :- * Project (82)
                        :  +- * BroadcastHashJoin Inner BuildRight (81)
                        :     :- * BroadcastHashJoin LeftSemi BuildRight (79)
                        :     :  :- * ColumnarToRow (77)
                        :     :  :  +- CometFilter (76)
                        :     :  :     +- CometScan parquet spark_catalog.default.store_sales (75)
                        :     :  +- ReusedExchange (78)
                        :     +- ReusedExchange (80)
                        +- ReusedExchange (83)


(1) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_item_sk#1, ss_quantity#2, ss_list_price#3, ss_sold_date_sk#4]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#4), dynamicpruningexpression(ss_sold_date_sk#4 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int,ss_quantity:int,ss_list_price:decimal(7,2)>

(2) CometFilter
Input [4]: [ss_item_sk#1, ss_quantity#2, ss_list_price#3, ss_sold_date_sk#4]
Condition : isnotnull(ss_item_sk#1)

(3) ColumnarToRow [codegen id : 11]
Input [4]: [ss_item_sk#1, ss_quantity#2, ss_list_price#3, ss_sold_date_sk#4]

(4) Scan parquet spark_catalog.default.item
Output [4]: [i_item_sk#6, i_brand_id#7, i_class_id#8, i_category_id#9]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)]
ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>

(5) CometFilter
Input [4]: [i_item_sk#6, i_brand_id#7, i_class_id#8, i_category_id#9]
Condition : ((isnotnull(i_brand_id#7) AND isnotnull(i_class_id#8)) AND isnotnull(i_category_id#9))

(6) ColumnarToRow [codegen id : 4]
Input [4]: [i_item_sk#6, i_brand_id#7, i_class_id#8, i_category_id#9]

(7) Scan parquet spark_catalog.default.store_sales
Output [2]: [ss_item_sk#10, ss_sold_date_sk#11]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#11), dynamicpruningexpression(ss_sold_date_sk#11 IN dynamicpruning#12)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int>

(8) CometFilter
Input [2]: [ss_item_sk#10, ss_sold_date_sk#11]
Condition : isnotnull(ss_item_sk#10)

(9) Scan parquet spark_catalog.default.item
Output [4]: [i_item_sk#13, i_brand_id#14, i_class_id#15, i_category_id#16]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)]
ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>

(10) CometFilter
Input [4]: [i_item_sk#13, i_brand_id#14, i_class_id#15, i_category_id#16]
Condition : (((isnotnull(i_item_sk#13) AND isnotnull(i_brand_id#14)) AND isnotnull(i_class_id#15)) AND isnotnull(i_category_id#16))

(11) Scan parquet spark_catalog.default.catalog_sales
Output [2]: [cs_item_sk#17, cs_sold_date_sk#18]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#18), dynamicpruningexpression(cs_sold_date_sk#18 IN dynamicpruning#19)]
PushedFilters: [IsNotNull(cs_item_sk)]
ReadSchema: struct<cs_item_sk:int>

(12) CometFilter
Input [2]: [cs_item_sk#17, cs_sold_date_sk#18]
Condition : isnotnull(cs_item_sk#17)

(13) Scan parquet spark_catalog.default.item
Output [4]: [i_item_sk#20, i_brand_id#21, i_class_id#22, i_category_id#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>

(14) CometFilter
Input [4]: [i_item_sk#20, i_brand_id#21, i_class_id#22, i_category_id#23]
Condition : isnotnull(i_item_sk#20)

(15) CometBroadcastExchange
Input [4]: [i_item_sk#20, i_brand_id#21, i_class_id#22, i_category_id#23]
Arguments: [i_item_sk#20, i_brand_id#21, i_class_id#22, i_category_id#23]

(16) CometBroadcastHashJoin
Left output [2]: [cs_item_sk#17, cs_sold_date_sk#18]
Right output [4]: [i_item_sk#20, i_brand_id#21, i_class_id#22, i_category_id#23]
Arguments: [cs_item_sk#17], [i_item_sk#20], Inner

(17) CometProject
Input [6]: [cs_item_sk#17, cs_sold_date_sk#18, i_item_sk#20, i_brand_id#21, i_class_id#22, i_category_id#23]
Arguments: [cs_sold_date_sk#18, i_brand_id#21, i_class_id#22, i_category_id#23], [cs_sold_date_sk#18, i_brand_id#21, i_class_id#22, i_category_id#23]

(18) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#24, d_year#25]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(19) CometFilter
Input [2]: [d_date_sk#24, d_year#25]
Condition : (((isnotnull(d_year#25) AND (d_year#25 >= 1998)) AND (d_year#25 <= 2000)) AND isnotnull(d_date_sk#24))

(20) CometProject
Input [2]: [d_date_sk#24, d_year#25]
Arguments: [d_date_sk#24], [d_date_sk#24]

(21) CometBroadcastExchange
Input [1]: [d_date_sk#24]
Arguments: [d_date_sk#24]

(22) CometBroadcastHashJoin
Left output [4]: [cs_sold_date_sk#18, i_brand_id#21, i_class_id#22, i_category_id#23]
Right output [1]: [d_date_sk#24]
Arguments: [cs_sold_date_sk#18], [d_date_sk#24], Inner

(23) CometProject
Input [5]: [cs_sold_date_sk#18, i_brand_id#21, i_class_id#22, i_category_id#23, d_date_sk#24]
Arguments: [i_brand_id#21, i_class_id#22, i_category_id#23], [i_brand_id#21, i_class_id#22, i_category_id#23]

(24) CometBroadcastExchange
Input [3]: [i_brand_id#21, i_class_id#22, i_category_id#23]
Arguments: [i_brand_id#21, i_class_id#22, i_category_id#23]

(25) CometBroadcastHashJoin
Left output [4]: [i_item_sk#13, i_brand_id#14, i_class_id#15, i_category_id#16]
Right output [3]: [i_brand_id#21, i_class_id#22, i_category_id#23]
Arguments: [coalesce(i_brand_id#14, 0), isnull(i_brand_id#14), coalesce(i_class_id#15, 0), isnull(i_class_id#15), coalesce(i_category_id#16, 0), isnull(i_category_id#16)], [coalesce(i_brand_id#21, 0), isnull(i_brand_id#21), coalesce(i_class_id#22, 0), isnull(i_class_id#22), coalesce(i_category_id#23, 0), isnull(i_category_id#23)], LeftSemi

(26) CometBroadcastExchange
Input [4]: [i_item_sk#13, i_brand_id#14, i_class_id#15, i_category_id#16]
Arguments: [i_item_sk#13, i_brand_id#14, i_class_id#15, i_category_id#16]

(27) CometBroadcastHashJoin
Left output [2]: [ss_item_sk#10, ss_sold_date_sk#11]
Right output [4]: [i_item_sk#13, i_brand_id#14, i_class_id#15, i_category_id#16]
Arguments: [ss_item_sk#10], [i_item_sk#13], Inner

(28) CometProject
Input [6]: [ss_item_sk#10, ss_sold_date_sk#11, i_item_sk#13, i_brand_id#14, i_class_id#15, i_category_id#16]
Arguments: [ss_sold_date_sk#11, i_brand_id#14, i_class_id#15, i_category_id#16], [ss_sold_date_sk#11, i_brand_id#14, i_class_id#15, i_category_id#16]

(29) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#26, d_year#27]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(30) CometFilter
Input [2]: [d_date_sk#26, d_year#27]
Condition : (((isnotnull(d_year#27) AND (d_year#27 >= 1998)) AND (d_year#27 <= 2000)) AND isnotnull(d_date_sk#26))

(31) CometProject
Input [2]: [d_date_sk#26, d_year#27]
Arguments: [d_date_sk#26], [d_date_sk#26]

(32) CometBroadcastExchange
Input [1]: [d_date_sk#26]
Arguments: [d_date_sk#26]

(33) CometBroadcastHashJoin
Left output [4]: [ss_sold_date_sk#11, i_brand_id#14, i_class_id#15, i_category_id#16]
Right output [1]: [d_date_sk#26]
Arguments: [ss_sold_date_sk#11], [d_date_sk#26], Inner

(34) CometProject
Input [5]: [ss_sold_date_sk#11, i_brand_id#14, i_class_id#15, i_category_id#16, d_date_sk#26]
Arguments: [brand_id#28, class_id#29, category_id#30], [i_brand_id#14 AS brand_id#28, i_class_id#15 AS class_id#29, i_category_id#16 AS category_id#30]

(35) CometHashAggregate
Input [3]: [brand_id#28, class_id#29, category_id#30]
Keys [3]: [brand_id#28, class_id#29, category_id#30]
Functions: []

(36) ColumnarToRow [codegen id : 1]
Input [3]: [brand_id#28, class_id#29, category_id#30]

(37) Exchange
Input [3]: [brand_id#28, class_id#29, category_id#30]
Arguments: hashpartitioning(brand_id#28, class_id#29, category_id#30, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(38) HashAggregate [codegen id : 3]
Input [3]: [brand_id#28, class_id#29, category_id#30]
Keys [3]: [brand_id#28, class_id#29, category_id#30]
Functions: []
Aggregate Attributes: []
Results [3]: [brand_id#28, class_id#29, category_id#30]

(39) Scan parquet spark_catalog.default.web_sales
Output [2]: [ws_item_sk#31, ws_sold_date_sk#32]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#32), dynamicpruningexpression(ws_sold_date_sk#32 IN dynamicpruning#33)]
PushedFilters: [IsNotNull(ws_item_sk)]
ReadSchema: struct<ws_item_sk:int>

(40) CometFilter
Input [2]: [ws_item_sk#31, ws_sold_date_sk#32]
Condition : isnotnull(ws_item_sk#31)

(41) Scan parquet spark_catalog.default.item
Output [4]: [i_item_sk#34, i_brand_id#35, i_class_id#36, i_category_id#37]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>

(42) CometFilter
Input [4]: [i_item_sk#34, i_brand_id#35, i_class_id#36, i_category_id#37]
Condition : isnotnull(i_item_sk#34)

(43) CometBroadcastExchange
Input [4]: [i_item_sk#34, i_brand_id#35, i_class_id#36, i_category_id#37]
Arguments: [i_item_sk#34, i_brand_id#35, i_class_id#36, i_category_id#37]

(44) CometBroadcastHashJoin
Left output [2]: [ws_item_sk#31, ws_sold_date_sk#32]
Right output [4]: [i_item_sk#34, i_brand_id#35, i_class_id#36, i_category_id#37]
Arguments: [ws_item_sk#31], [i_item_sk#34], Inner

(45) CometProject
Input [6]: [ws_item_sk#31, ws_sold_date_sk#32, i_item_sk#34, i_brand_id#35, i_class_id#36, i_category_id#37]
Arguments: [ws_sold_date_sk#32, i_brand_id#35, i_class_id#36, i_category_id#37], [ws_sold_date_sk#32, i_brand_id#35, i_class_id#36, i_category_id#37]

(46) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#38, d_year#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(47) CometFilter
Input [2]: [d_date_sk#38, d_year#39]
Condition : (((isnotnull(d_year#39) AND (d_year#39 >= 1998)) AND (d_year#39 <= 2000)) AND isnotnull(d_date_sk#38))

(48) CometProject
Input [2]: [d_date_sk#38, d_year#39]
Arguments: [d_date_sk#38], [d_date_sk#38]

(49) CometBroadcastExchange
Input [1]: [d_date_sk#38]
Arguments: [d_date_sk#38]

(50) CometBroadcastHashJoin
Left output [4]: [ws_sold_date_sk#32, i_brand_id#35, i_class_id#36, i_category_id#37]
Right output [1]: [d_date_sk#38]
Arguments: [ws_sold_date_sk#32], [d_date_sk#38], Inner

(51) CometProject
Input [5]: [ws_sold_date_sk#32, i_brand_id#35, i_class_id#36, i_category_id#37, d_date_sk#38]
Arguments: [i_brand_id#35, i_class_id#36, i_category_id#37], [i_brand_id#35, i_class_id#36, i_category_id#37]

(52) ColumnarToRow [codegen id : 2]
Input [3]: [i_brand_id#35, i_class_id#36, i_category_id#37]

(53) BroadcastExchange
Input [3]: [i_brand_id#35, i_class_id#36, i_category_id#37]
Arguments: HashedRelationBroadcastMode(List(coalesce(input[0, int, true], 0), isnull(input[0, int, true]), coalesce(input[1, int, true], 0), isnull(input[1, int, true]), coalesce(input[2, int, true], 0), isnull(input[2, int, true])),false), [plan_id=2]

(54) BroadcastHashJoin [codegen id : 3]
Left keys [6]: [coalesce(brand_id#28, 0), isnull(brand_id#28), coalesce(class_id#29, 0), isnull(class_id#29), coalesce(category_id#30, 0), isnull(category_id#30)]
Right keys [6]: [coalesce(i_brand_id#35, 0), isnull(i_brand_id#35), coalesce(i_class_id#36, 0), isnull(i_class_id#36), coalesce(i_category_id#37, 0), isnull(i_category_id#37)]
Join type: LeftSemi
Join condition: None

(55) BroadcastExchange
Input [3]: [brand_id#28, class_id#29, category_id#30]
Arguments: HashedRelationBroadcastMode(List(input[0, int, true], input[1, int, true], input[2, int, true]),false), [plan_id=3]

(56) BroadcastHashJoin [codegen id : 4]
Left keys [3]: [i_brand_id#7, i_class_id#8, i_category_id#9]
Right keys [3]: [brand_id#28, class_id#29, category_id#30]
Join type: Inner
Join condition: None

(57) Project [codegen id : 4]
Output [1]: [i_item_sk#6 AS ss_item_sk#40]
Input [7]: [i_item_sk#6, i_brand_id#7, i_class_id#8, i_category_id#9, brand_id#28, class_id#29, category_id#30]

(58) BroadcastExchange
Input [1]: [ss_item_sk#40]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(59) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [ss_item_sk#40]
Join type: LeftSemi
Join condition: None

(60) Scan parquet spark_catalog.default.item
Output [4]: [i_item_sk#41, i_brand_id#42, i_class_id#43, i_category_id#44]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)]
ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>

(61) CometFilter
Input [4]: [i_item_sk#41, i_brand_id#42, i_class_id#43, i_category_id#44]
Condition : (((isnotnull(i_item_sk#41) AND isnotnull(i_brand_id#42)) AND isnotnull(i_class_id#43)) AND isnotnull(i_category_id#44))

(62) ColumnarToRow [codegen id : 9]
Input [4]: [i_item_sk#41, i_brand_id#42, i_class_id#43, i_category_id#44]

(63) ReusedExchange [Reuses operator id: 58]
Output [1]: [ss_item_sk#40]

(64) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [i_item_sk#41]
Right keys [1]: [ss_item_sk#40]
Join type: LeftSemi
Join condition: None

(65) BroadcastExchange
Input [4]: [i_item_sk#41, i_brand_id#42, i_class_id#43, i_category_id#44]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(66) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#41]
Join type: Inner
Join condition: None

(67) Project [codegen id : 11]
Output [6]: [ss_quantity#2, ss_list_price#3, ss_sold_date_sk#4, i_brand_id#42, i_class_id#43, i_category_id#44]
Input [8]: [ss_item_sk#1, ss_quantity#2, ss_list_price#3, ss_sold_date_sk#4, i_item_sk#41, i_brand_id#42, i_class_id#43, i_category_id#44]

(68) ReusedExchange [Reuses operator id: 123]
Output [1]: [d_date_sk#45]

(69) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [ss_sold_date_sk#4]
Right keys [1]: [d_date_sk#45]
Join type: Inner
Join condition: None

(70) Project [codegen id : 11]
Output [5]: [ss_quantity#2, ss_list_price#3, i_brand_id#42, i_class_id#43, i_category_id#44]
Input [7]: [ss_quantity#2, ss_list_price#3, ss_sold_date_sk#4, i_brand_id#42, i_class_id#43, i_category_id#44, d_date_sk#45]

(71) HashAggregate [codegen id : 11]
Input [5]: [ss_quantity#2, ss_list_price#3, i_brand_id#42, i_class_id#43, i_category_id#44]
Keys [3]: [i_brand_id#42, i_class_id#43, i_category_id#44]
Functions [2]: [partial_sum((cast(ss_quantity#2 as decimal(10,0)) * ss_list_price#3)), partial_count(1)]
Aggregate Attributes [3]: [sum#46, isEmpty#47, count#48]
Results [6]: [i_brand_id#42, i_class_id#43, i_category_id#44, sum#49, isEmpty#50, count#51]

(72) Exchange
Input [6]: [i_brand_id#42, i_class_id#43, i_category_id#44, sum#49, isEmpty#50, count#51]
Arguments: hashpartitioning(i_brand_id#42, i_class_id#43, i_category_id#44, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(73) HashAggregate [codegen id : 24]
Input [6]: [i_brand_id#42, i_class_id#43, i_category_id#44, sum#49, isEmpty#50, count#51]
Keys [3]: [i_brand_id#42, i_class_id#43, i_category_id#44]
Functions [2]: [sum((cast(ss_quantity#2 as decimal(10,0)) * ss_list_price#3)), count(1)]
Aggregate Attributes [2]: [sum((cast(ss_quantity#2 as decimal(10,0)) * ss_list_price#3))#52, count(1)#53]
Results [6]: [store AS channel#54, i_brand_id#42, i_class_id#43, i_category_id#44, sum((cast(ss_quantity#2 as decimal(10,0)) * ss_list_price#3))#52 AS sales#55, count(1)#53 AS number_sales#56]

(74) Filter [codegen id : 24]
Input [6]: [channel#54, i_brand_id#42, i_class_id#43, i_category_id#44, sales#55, number_sales#56]
Condition : (isnotnull(sales#55) AND (cast(sales#55 as decimal(32,6)) > cast(Subquery scalar-subquery#57, [id=#58] as decimal(32,6))))

(75) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_item_sk#59, ss_quantity#60, ss_list_price#61, ss_sold_date_sk#62]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#62), dynamicpruningexpression(ss_sold_date_sk#62 IN dynamicpruning#63)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int,ss_quantity:int,ss_list_price:decimal(7,2)>

(76) CometFilter
Input [4]: [ss_item_sk#59, ss_quantity#60, ss_list_price#61, ss_sold_date_sk#62]
Condition : isnotnull(ss_item_sk#59)

(77) ColumnarToRow [codegen id : 22]
Input [4]: [ss_item_sk#59, ss_quantity#60, ss_list_price#61, ss_sold_date_sk#62]

(78) ReusedExchange [Reuses operator id: 58]
Output [1]: [ss_item_sk#40]

(79) BroadcastHashJoin [codegen id : 22]
Left keys [1]: [ss_item_sk#59]
Right keys [1]: [ss_item_sk#40]
Join type: LeftSemi
Join condition: None

(80) ReusedExchange [Reuses operator id: 65]
Output [4]: [i_item_sk#64, i_brand_id#65, i_class_id#66, i_category_id#67]

(81) BroadcastHashJoin [codegen id : 22]
Left keys [1]: [ss_item_sk#59]
Right keys [1]: [i_item_sk#64]
Join type: Inner
Join condition: None

(82) Project [codegen id : 22]
Output [6]: [ss_quantity#60, ss_list_price#61, ss_sold_date_sk#62, i_brand_id#65, i_class_id#66, i_category_id#67]
Input [8]: [ss_item_sk#59, ss_quantity#60, ss_list_price#61, ss_sold_date_sk#62, i_item_sk#64, i_brand_id#65, i_class_id#66, i_category_id#67]

(83) ReusedExchange [Reuses operator id: 137]
Output [1]: [d_date_sk#68]

(84) BroadcastHashJoin [codegen id : 22]
Left keys [1]: [ss_sold_date_sk#62]
Right keys [1]: [d_date_sk#68]
Join type: Inner
Join condition: None

(85) Project [codegen id : 22]
Output [5]: [ss_quantity#60, ss_list_price#61, i_brand_id#65, i_class_id#66, i_category_id#67]
Input [7]: [ss_quantity#60, ss_list_price#61, ss_sold_date_sk#62, i_brand_id#65, i_class_id#66, i_category_id#67, d_date_sk#68]

(86) HashAggregate [codegen id : 22]
Input [5]: [ss_quantity#60, ss_list_price#61, i_brand_id#65, i_class_id#66, i_category_id#67]
Keys [3]: [i_brand_id#65, i_class_id#66, i_category_id#67]
Functions [2]: [partial_sum((cast(ss_quantity#60 as decimal(10,0)) * ss_list_price#61)), partial_count(1)]
Aggregate Attributes [3]: [sum#69, isEmpty#70, count#71]
Results [6]: [i_brand_id#65, i_class_id#66, i_category_id#67, sum#72, isEmpty#73, count#74]

(87) Exchange
Input [6]: [i_brand_id#65, i_class_id#66, i_category_id#67, sum#72, isEmpty#73, count#74]
Arguments: hashpartitioning(i_brand_id#65, i_class_id#66, i_category_id#67, 5), ENSURE_REQUIREMENTS, [plan_id=7]

(88) HashAggregate [codegen id : 23]
Input [6]: [i_brand_id#65, i_class_id#66, i_category_id#67, sum#72, isEmpty#73, count#74]
Keys [3]: [i_brand_id#65, i_class_id#66, i_category_id#67]
Functions [2]: [sum((cast(ss_quantity#60 as decimal(10,0)) * ss_list_price#61)), count(1)]
Aggregate Attributes [2]: [sum((cast(ss_quantity#60 as decimal(10,0)) * ss_list_price#61))#75, count(1)#76]
Results [6]: [store AS channel#77, i_brand_id#65, i_class_id#66, i_category_id#67, sum((cast(ss_quantity#60 as decimal(10,0)) * ss_list_price#61))#75 AS sales#78, count(1)#76 AS number_sales#79]

(89) Filter [codegen id : 23]
Input [6]: [channel#77, i_brand_id#65, i_class_id#66, i_category_id#67, sales#78, number_sales#79]
Condition : (isnotnull(sales#78) AND (cast(sales#78 as decimal(32,6)) > cast(ReusedSubquery Subquery scalar-subquery#57, [id=#58] as decimal(32,6))))

(90) BroadcastExchange
Input [6]: [channel#77, i_brand_id#65, i_class_id#66, i_category_id#67, sales#78, number_sales#79]
Arguments: HashedRelationBroadcastMode(List(input[1, int, true], input[2, int, true], input[3, int, true]),false), [plan_id=8]

(91) BroadcastHashJoin [codegen id : 24]
Left keys [3]: [i_brand_id#42, i_class_id#43, i_category_id#44]
Right keys [3]: [i_brand_id#65, i_class_id#66, i_category_id#67]
Join type: Inner
Join condition: None

(92) TakeOrderedAndProject
Input [12]: [channel#54, i_brand_id#42, i_class_id#43, i_category_id#44, sales#55, number_sales#56, channel#77, i_brand_id#65, i_class_id#66, i_category_id#67, sales#78, number_sales#79]
Arguments: 100, [i_brand_id#42 ASC NULLS FIRST, i_class_id#43 ASC NULLS FIRST, i_category_id#44 ASC NULLS FIRST], [channel#54, i_brand_id#42, i_class_id#43, i_category_id#44, sales#55, number_sales#56, channel#77, i_brand_id#65, i_class_id#66, i_category_id#67, sales#78, number_sales#79]

===== Subqueries =====

Subquery:1 Hosting operator id = 74 Hosting Expression = Subquery scalar-subquery#57, [id=#58]
* HashAggregate (118)
+- Exchange (117)
   +- * ColumnarToRow (116)
      +- CometHashAggregate (115)
         +- CometUnion (114)
            :- CometProject (99)
            :  +- CometBroadcastHashJoin (98)
            :     :- CometScan parquet spark_catalog.default.store_sales (93)
            :     +- CometBroadcastExchange (97)
            :        +- CometProject (96)
            :           +- CometFilter (95)
            :              +- CometScan parquet spark_catalog.default.date_dim (94)
            :- CometProject (106)
            :  +- CometBroadcastHashJoin (105)
            :     :- CometScan parquet spark_catalog.default.catalog_sales (100)
            :     +- CometBroadcastExchange (104)
            :        +- CometProject (103)
            :           +- CometFilter (102)
            :              +- CometScan parquet spark_catalog.default.date_dim (101)
            +- CometProject (113)
               +- CometBroadcastHashJoin (112)
                  :- CometScan parquet spark_catalog.default.web_sales (107)
                  +- CometBroadcastExchange (111)
                     +- CometProject (110)
                        +- CometFilter (109)
                           +- CometScan parquet spark_catalog.default.date_dim (108)


(93) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_quantity#80, ss_list_price#81, ss_sold_date_sk#82]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#82), dynamicpruningexpression(ss_sold_date_sk#82 IN dynamicpruning#83)]
ReadSchema: struct<ss_quantity:int,ss_list_price:decimal(7,2)>

(94) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#84, d_year#85]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(95) CometFilter
Input [2]: [d_date_sk#84, d_year#85]
Condition : (((isnotnull(d_year#85) AND (d_year#85 >= 1998)) AND (d_year#85 <= 2000)) AND isnotnull(d_date_sk#84))

(96) CometProject
Input [2]: [d_date_sk#84, d_year#85]
Arguments: [d_date_sk#84], [d_date_sk#84]

(97) CometBroadcastExchange
Input [1]: [d_date_sk#84]
Arguments: [d_date_sk#84]

(98) CometBroadcastHashJoin
Left output [3]: [ss_quantity#80, ss_list_price#81, ss_sold_date_sk#82]
Right output [1]: [d_date_sk#84]
Arguments: [ss_sold_date_sk#82], [d_date_sk#84], Inner

(99) CometProject
Input [4]: [ss_quantity#80, ss_list_price#81, ss_sold_date_sk#82, d_date_sk#84]
Arguments: [quantity#86, list_price#87], [ss_quantity#80 AS quantity#86, ss_list_price#81 AS list_price#87]

(100) Scan parquet spark_catalog.default.catalog_sales
Output [3]: [cs_quantity#88, cs_list_price#89, cs_sold_date_sk#90]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#90), dynamicpruningexpression(cs_sold_date_sk#90 IN dynamicpruning#91)]
ReadSchema: struct<cs_quantity:int,cs_list_price:decimal(7,2)>

(101) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#92, d_year#93]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(102) CometFilter
Input [2]: [d_date_sk#92, d_year#93]
Condition : (((isnotnull(d_year#93) AND (d_year#93 >= 1998)) AND (d_year#93 <= 2000)) AND isnotnull(d_date_sk#92))

(103) CometProject
Input [2]: [d_date_sk#92, d_year#93]
Arguments: [d_date_sk#92], [d_date_sk#92]

(104) CometBroadcastExchange
Input [1]: [d_date_sk#92]
Arguments: [d_date_sk#92]

(105) CometBroadcastHashJoin
Left output [3]: [cs_quantity#88, cs_list_price#89, cs_sold_date_sk#90]
Right output [1]: [d_date_sk#92]
Arguments: [cs_sold_date_sk#90], [d_date_sk#92], Inner

(106) CometProject
Input [4]: [cs_quantity#88, cs_list_price#89, cs_sold_date_sk#90, d_date_sk#92]
Arguments: [quantity#94, list_price#95], [cs_quantity#88 AS quantity#94, cs_list_price#89 AS list_price#95]

(107) Scan parquet spark_catalog.default.web_sales
Output [3]: [ws_quantity#96, ws_list_price#97, ws_sold_date_sk#98]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#98), dynamicpruningexpression(ws_sold_date_sk#98 IN dynamicpruning#99)]
ReadSchema: struct<ws_quantity:int,ws_list_price:decimal(7,2)>

(108) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#100, d_year#101]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(109) CometFilter
Input [2]: [d_date_sk#100, d_year#101]
Condition : (((isnotnull(d_year#101) AND (d_year#101 >= 1998)) AND (d_year#101 <= 2000)) AND isnotnull(d_date_sk#100))

(110) CometProject
Input [2]: [d_date_sk#100, d_year#101]
Arguments: [d_date_sk#100], [d_date_sk#100]

(111) CometBroadcastExchange
Input [1]: [d_date_sk#100]
Arguments: [d_date_sk#100]

(112) CometBroadcastHashJoin
Left output [3]: [ws_quantity#96, ws_list_price#97, ws_sold_date_sk#98]
Right output [1]: [d_date_sk#100]
Arguments: [ws_sold_date_sk#98], [d_date_sk#100], Inner

(113) CometProject
Input [4]: [ws_quantity#96, ws_list_price#97, ws_sold_date_sk#98, d_date_sk#100]
Arguments: [quantity#102, list_price#103], [ws_quantity#96 AS quantity#102, ws_list_price#97 AS list_price#103]

(114) CometUnion
Child 0 Input [2]: [quantity#86, list_price#87]
Child 1 Input [2]: [quantity#94, list_price#95]
Child 2 Input [2]: [quantity#102, list_price#103]

(115) CometHashAggregate
Input [2]: [quantity#86, list_price#87]
Keys: []
Functions [1]: [partial_avg((cast(quantity#86 as decimal(10,0)) * list_price#87))]

(116) ColumnarToRow [codegen id : 1]
Input [2]: [sum#104, count#105]

(117) Exchange
Input [2]: [sum#104, count#105]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=9]

(118) HashAggregate [codegen id : 2]
Input [2]: [sum#104, count#105]
Keys: []
Functions [1]: [avg((cast(quantity#86 as decimal(10,0)) * list_price#87))]
Aggregate Attributes [1]: [avg((cast(quantity#86 as decimal(10,0)) * list_price#87))#106]
Results [1]: [avg((cast(quantity#86 as decimal(10,0)) * list_price#87))#106 AS average_sales#107]

Subquery:2 Hosting operator id = 93 Hosting Expression = ss_sold_date_sk#82 IN dynamicpruning#12

Subquery:3 Hosting operator id = 100 Hosting Expression = cs_sold_date_sk#90 IN dynamicpruning#12

Subquery:4 Hosting operator id = 107 Hosting Expression = ws_sold_date_sk#98 IN dynamicpruning#12

Subquery:5 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#4 IN dynamicpruning#5
BroadcastExchange (123)
+- * ColumnarToRow (122)
   +- CometProject (121)
      +- CometFilter (120)
         +- CometScan parquet spark_catalog.default.date_dim (119)


(119) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#45, d_week_seq#108]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_week_seq), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_week_seq:int>

(120) CometFilter
Input [2]: [d_date_sk#45, d_week_seq#108]
Condition : ((isnotnull(d_week_seq#108) AND (d_week_seq#108 = Subquery scalar-subquery#109, [id=#110])) AND isnotnull(d_date_sk#45))

(121) CometProject
Input [2]: [d_date_sk#45, d_week_seq#108]
Arguments: [d_date_sk#45], [d_date_sk#45]

(122) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#45]

(123) BroadcastExchange
Input [1]: [d_date_sk#45]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=10]

Subquery:6 Hosting operator id = 120 Hosting Expression = Subquery scalar-subquery#109, [id=#110]
* ColumnarToRow (127)
+- CometProject (126)
   +- CometFilter (125)
      +- CometScan parquet spark_catalog.default.date_dim (124)


(124) Scan parquet spark_catalog.default.date_dim
Output [4]: [d_week_seq#111, d_year#112, d_moy#113, d_dom#114]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), IsNotNull(d_dom), EqualTo(d_year,1999), EqualTo(d_moy,12), EqualTo(d_dom,16)]
ReadSchema: struct<d_week_seq:int,d_year:int,d_moy:int,d_dom:int>

(125) CometFilter
Input [4]: [d_week_seq#111, d_year#112, d_moy#113, d_dom#114]
Condition : (((((isnotnull(d_year#112) AND isnotnull(d_moy#113)) AND isnotnull(d_dom#114)) AND (d_year#112 = 1999)) AND (d_moy#113 = 12)) AND (d_dom#114 = 16))

(126) CometProject
Input [4]: [d_week_seq#111, d_year#112, d_moy#113, d_dom#114]
Arguments: [d_week_seq#111], [d_week_seq#111]

(127) ColumnarToRow [codegen id : 1]
Input [1]: [d_week_seq#111]

Subquery:7 Hosting operator id = 7 Hosting Expression = ss_sold_date_sk#11 IN dynamicpruning#12
BroadcastExchange (132)
+- * ColumnarToRow (131)
   +- CometProject (130)
      +- CometFilter (129)
         +- CometScan parquet spark_catalog.default.date_dim (128)


(128) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#26, d_year#27]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(129) CometFilter
Input [2]: [d_date_sk#26, d_year#27]
Condition : (((isnotnull(d_year#27) AND (d_year#27 >= 1998)) AND (d_year#27 <= 2000)) AND isnotnull(d_date_sk#26))

(130) CometProject
Input [2]: [d_date_sk#26, d_year#27]
Arguments: [d_date_sk#26], [d_date_sk#26]

(131) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#26]

(132) BroadcastExchange
Input [1]: [d_date_sk#26]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=11]

Subquery:8 Hosting operator id = 11 Hosting Expression = cs_sold_date_sk#18 IN dynamicpruning#12

Subquery:9 Hosting operator id = 39 Hosting Expression = ws_sold_date_sk#32 IN dynamicpruning#12

Subquery:10 Hosting operator id = 89 Hosting Expression = ReusedSubquery Subquery scalar-subquery#57, [id=#58]

Subquery:11 Hosting operator id = 75 Hosting Expression = ss_sold_date_sk#62 IN dynamicpruning#63
BroadcastExchange (137)
+- * ColumnarToRow (136)
   +- CometProject (135)
      +- CometFilter (134)
         +- CometScan parquet spark_catalog.default.date_dim (133)


(133) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#68, d_week_seq#115]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_week_seq), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_week_seq:int>

(134) CometFilter
Input [2]: [d_date_sk#68, d_week_seq#115]
Condition : ((isnotnull(d_week_seq#115) AND (d_week_seq#115 = Subquery scalar-subquery#116, [id=#117])) AND isnotnull(d_date_sk#68))

(135) CometProject
Input [2]: [d_date_sk#68, d_week_seq#115]
Arguments: [d_date_sk#68], [d_date_sk#68]

(136) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#68]

(137) BroadcastExchange
Input [1]: [d_date_sk#68]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=12]

Subquery:12 Hosting operator id = 134 Hosting Expression = Subquery scalar-subquery#116, [id=#117]
* ColumnarToRow (141)
+- CometProject (140)
   +- CometFilter (139)
      +- CometScan parquet spark_catalog.default.date_dim (138)


(138) Scan parquet spark_catalog.default.date_dim
Output [4]: [d_week_seq#118, d_year#119, d_moy#120, d_dom#121]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), IsNotNull(d_dom), EqualTo(d_year,1998), EqualTo(d_moy,12), EqualTo(d_dom,16)]
ReadSchema: struct<d_week_seq:int,d_year:int,d_moy:int,d_dom:int>

(139) CometFilter
Input [4]: [d_week_seq#118, d_year#119, d_moy#120, d_dom#121]
Condition : (((((isnotnull(d_year#119) AND isnotnull(d_moy#120)) AND isnotnull(d_dom#121)) AND (d_year#119 = 1998)) AND (d_moy#120 = 12)) AND (d_dom#121 = 16))

(140) CometProject
Input [4]: [d_week_seq#118, d_year#119, d_moy#120, d_dom#121]
Arguments: [d_week_seq#118], [d_week_seq#118]

(141) ColumnarToRow [codegen id : 1]
Input [1]: [d_week_seq#118]


