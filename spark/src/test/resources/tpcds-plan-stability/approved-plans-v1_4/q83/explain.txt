== Physical Plan ==
TakeOrderedAndProject (64)
+- * Project (63)
   +- * BroadcastHashJoin Inner BuildRight (62)
      :- * Project (41)
      :  +- * BroadcastHashJoin Inner BuildRight (40)
      :     :- * HashAggregate (19)
      :     :  +- Exchange (18)
      :     :     +- * ColumnarToRow (17)
      :     :        +- CometHashAggregate (16)
      :     :           +- CometProject (15)
      :     :              +- CometBroadcastHashJoin (14)
      :     :                 :- CometProject (7)
      :     :                 :  +- CometBroadcastHashJoin (6)
      :     :                 :     :- CometFilter (2)
      :     :                 :     :  +- CometScan parquet spark_catalog.default.store_returns (1)
      :     :                 :     +- CometBroadcastExchange (5)
      :     :                 :        +- CometFilter (4)
      :     :                 :           +- CometScan parquet spark_catalog.default.item (3)
      :     :                 +- CometBroadcastExchange (13)
      :     :                    +- CometProject (12)
      :     :                       +- CometBroadcastHashJoin (11)
      :     :                          :- CometFilter (9)
      :     :                          :  +- CometScan parquet spark_catalog.default.date_dim (8)
      :     :                          +- ReusedExchange (10)
      :     +- BroadcastExchange (39)
      :        +- * HashAggregate (38)
      :           +- Exchange (37)
      :              +- * ColumnarToRow (36)
      :                 +- CometHashAggregate (35)
      :                    +- CometProject (34)
      :                       +- CometBroadcastHashJoin (33)
      :                          :- CometProject (26)
      :                          :  +- CometBroadcastHashJoin (25)
      :                          :     :- CometFilter (21)
      :                          :     :  +- CometScan parquet spark_catalog.default.catalog_returns (20)
      :                          :     +- CometBroadcastExchange (24)
      :                          :        +- CometFilter (23)
      :                          :           +- CometScan parquet spark_catalog.default.item (22)
      :                          +- CometBroadcastExchange (32)
      :                             +- CometProject (31)
      :                                +- CometBroadcastHashJoin (30)
      :                                   :- CometFilter (28)
      :                                   :  +- CometScan parquet spark_catalog.default.date_dim (27)
      :                                   +- ReusedExchange (29)
      +- BroadcastExchange (61)
         +- * HashAggregate (60)
            +- Exchange (59)
               +- * ColumnarToRow (58)
                  +- CometHashAggregate (57)
                     +- CometProject (56)
                        +- CometBroadcastHashJoin (55)
                           :- CometProject (48)
                           :  +- CometBroadcastHashJoin (47)
                           :     :- CometFilter (43)
                           :     :  +- CometScan parquet spark_catalog.default.web_returns (42)
                           :     +- CometBroadcastExchange (46)
                           :        +- CometFilter (45)
                           :           +- CometScan parquet spark_catalog.default.item (44)
                           +- CometBroadcastExchange (54)
                              +- CometProject (53)
                                 +- CometBroadcastHashJoin (52)
                                    :- CometFilter (50)
                                    :  +- CometScan parquet spark_catalog.default.date_dim (49)
                                    +- ReusedExchange (51)


(1) Scan parquet spark_catalog.default.store_returns
Output [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(sr_returned_date_sk#3), dynamicpruningexpression(sr_returned_date_sk#3 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(sr_item_sk)]
ReadSchema: struct<sr_item_sk:int,sr_return_quantity:int>

(2) CometFilter
Input [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Condition : isnotnull(sr_item_sk#1)

(3) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#5, i_item_id#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_item_id)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(4) CometFilter
Input [2]: [i_item_sk#5, i_item_id#6]
Condition : (isnotnull(i_item_sk#5) AND isnotnull(i_item_id#6))

(5) CometBroadcastExchange
Input [2]: [i_item_sk#5, i_item_id#6]
Arguments: [i_item_sk#5, i_item_id#6]

(6) CometBroadcastHashJoin
Left output [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Right output [2]: [i_item_sk#5, i_item_id#6]
Arguments: [sr_item_sk#1], [i_item_sk#5], Inner

(7) CometProject
Input [5]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3, i_item_sk#5, i_item_id#6]
Arguments: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6], [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6]

(8) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#7, d_date#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(9) CometFilter
Input [2]: [d_date_sk#7, d_date#8]
Condition : isnotnull(d_date_sk#7)

(10) ReusedExchange [Reuses operator id: 74]
Output [1]: [d_date#9]

(11) CometBroadcastHashJoin
Left output [2]: [d_date_sk#7, d_date#8]
Right output [1]: [d_date#9]
Arguments: [d_date#8], [d_date#9], LeftSemi

(12) CometProject
Input [2]: [d_date_sk#7, d_date#8]
Arguments: [d_date_sk#7], [d_date_sk#7]

(13) CometBroadcastExchange
Input [1]: [d_date_sk#7]
Arguments: [d_date_sk#7]

(14) CometBroadcastHashJoin
Left output [3]: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6]
Right output [1]: [d_date_sk#7]
Arguments: [sr_returned_date_sk#3], [d_date_sk#7], Inner

(15) CometProject
Input [4]: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6, d_date_sk#7]
Arguments: [sr_return_quantity#2, i_item_id#6], [sr_return_quantity#2, i_item_id#6]

(16) CometHashAggregate
Input [2]: [sr_return_quantity#2, i_item_id#6]
Keys [1]: [i_item_id#6]
Functions [1]: [partial_sum(sr_return_quantity#2)]

(17) ColumnarToRow [codegen id : 1]
Input [2]: [i_item_id#6, sum#10]

(18) Exchange
Input [2]: [i_item_id#6, sum#10]
Arguments: hashpartitioning(i_item_id#6, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(19) HashAggregate [codegen id : 6]
Input [2]: [i_item_id#6, sum#10]
Keys [1]: [i_item_id#6]
Functions [1]: [sum(sr_return_quantity#2)]
Aggregate Attributes [1]: [sum(sr_return_quantity#2)#11]
Results [2]: [i_item_id#6 AS item_id#12, sum(sr_return_quantity#2)#11 AS sr_item_qty#13]

(20) Scan parquet spark_catalog.default.catalog_returns
Output [3]: [cr_item_sk#14, cr_return_quantity#15, cr_returned_date_sk#16]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cr_returned_date_sk#16), dynamicpruningexpression(cr_returned_date_sk#16 IN dynamicpruning#17)]
PushedFilters: [IsNotNull(cr_item_sk)]
ReadSchema: struct<cr_item_sk:int,cr_return_quantity:int>

(21) CometFilter
Input [3]: [cr_item_sk#14, cr_return_quantity#15, cr_returned_date_sk#16]
Condition : isnotnull(cr_item_sk#14)

(22) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#18, i_item_id#19]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_item_id)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(23) CometFilter
Input [2]: [i_item_sk#18, i_item_id#19]
Condition : (isnotnull(i_item_sk#18) AND isnotnull(i_item_id#19))

(24) CometBroadcastExchange
Input [2]: [i_item_sk#18, i_item_id#19]
Arguments: [i_item_sk#18, i_item_id#19]

(25) CometBroadcastHashJoin
Left output [3]: [cr_item_sk#14, cr_return_quantity#15, cr_returned_date_sk#16]
Right output [2]: [i_item_sk#18, i_item_id#19]
Arguments: [cr_item_sk#14], [i_item_sk#18], Inner

(26) CometProject
Input [5]: [cr_item_sk#14, cr_return_quantity#15, cr_returned_date_sk#16, i_item_sk#18, i_item_id#19]
Arguments: [cr_return_quantity#15, cr_returned_date_sk#16, i_item_id#19], [cr_return_quantity#15, cr_returned_date_sk#16, i_item_id#19]

(27) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#20, d_date#21]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(28) CometFilter
Input [2]: [d_date_sk#20, d_date#21]
Condition : isnotnull(d_date_sk#20)

(29) ReusedExchange [Reuses operator id: 88]
Output [1]: [d_date#22]

(30) CometBroadcastHashJoin
Left output [2]: [d_date_sk#20, d_date#21]
Right output [1]: [d_date#22]
Arguments: [d_date#21], [d_date#22], LeftSemi

(31) CometProject
Input [2]: [d_date_sk#20, d_date#21]
Arguments: [d_date_sk#20], [d_date_sk#20]

(32) CometBroadcastExchange
Input [1]: [d_date_sk#20]
Arguments: [d_date_sk#20]

(33) CometBroadcastHashJoin
Left output [3]: [cr_return_quantity#15, cr_returned_date_sk#16, i_item_id#19]
Right output [1]: [d_date_sk#20]
Arguments: [cr_returned_date_sk#16], [d_date_sk#20], Inner

(34) CometProject
Input [4]: [cr_return_quantity#15, cr_returned_date_sk#16, i_item_id#19, d_date_sk#20]
Arguments: [cr_return_quantity#15, i_item_id#19], [cr_return_quantity#15, i_item_id#19]

(35) CometHashAggregate
Input [2]: [cr_return_quantity#15, i_item_id#19]
Keys [1]: [i_item_id#19]
Functions [1]: [partial_sum(cr_return_quantity#15)]

(36) ColumnarToRow [codegen id : 2]
Input [2]: [i_item_id#19, sum#23]

(37) Exchange
Input [2]: [i_item_id#19, sum#23]
Arguments: hashpartitioning(i_item_id#19, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(38) HashAggregate [codegen id : 3]
Input [2]: [i_item_id#19, sum#23]
Keys [1]: [i_item_id#19]
Functions [1]: [sum(cr_return_quantity#15)]
Aggregate Attributes [1]: [sum(cr_return_quantity#15)#24]
Results [2]: [i_item_id#19 AS item_id#25, sum(cr_return_quantity#15)#24 AS cr_item_qty#26]

(39) BroadcastExchange
Input [2]: [item_id#25, cr_item_qty#26]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=3]

(40) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [item_id#12]
Right keys [1]: [item_id#25]
Join type: Inner
Join condition: None

(41) Project [codegen id : 6]
Output [3]: [item_id#12, sr_item_qty#13, cr_item_qty#26]
Input [4]: [item_id#12, sr_item_qty#13, item_id#25, cr_item_qty#26]

(42) Scan parquet spark_catalog.default.web_returns
Output [3]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(wr_returned_date_sk#29), dynamicpruningexpression(wr_returned_date_sk#29 IN dynamicpruning#30)]
PushedFilters: [IsNotNull(wr_item_sk)]
ReadSchema: struct<wr_item_sk:int,wr_return_quantity:int>

(43) CometFilter
Input [3]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29]
Condition : isnotnull(wr_item_sk#27)

(44) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#31, i_item_id#32]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_item_id)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(45) CometFilter
Input [2]: [i_item_sk#31, i_item_id#32]
Condition : (isnotnull(i_item_sk#31) AND isnotnull(i_item_id#32))

(46) CometBroadcastExchange
Input [2]: [i_item_sk#31, i_item_id#32]
Arguments: [i_item_sk#31, i_item_id#32]

(47) CometBroadcastHashJoin
Left output [3]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29]
Right output [2]: [i_item_sk#31, i_item_id#32]
Arguments: [wr_item_sk#27], [i_item_sk#31], Inner

(48) CometProject
Input [5]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29, i_item_sk#31, i_item_id#32]
Arguments: [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32], [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32]

(49) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#33, d_date#34]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(50) CometFilter
Input [2]: [d_date_sk#33, d_date#34]
Condition : isnotnull(d_date_sk#33)

(51) ReusedExchange [Reuses operator id: 102]
Output [1]: [d_date#35]

(52) CometBroadcastHashJoin
Left output [2]: [d_date_sk#33, d_date#34]
Right output [1]: [d_date#35]
Arguments: [d_date#34], [d_date#35], LeftSemi

(53) CometProject
Input [2]: [d_date_sk#33, d_date#34]
Arguments: [d_date_sk#33], [d_date_sk#33]

(54) CometBroadcastExchange
Input [1]: [d_date_sk#33]
Arguments: [d_date_sk#33]

(55) CometBroadcastHashJoin
Left output [3]: [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32]
Right output [1]: [d_date_sk#33]
Arguments: [wr_returned_date_sk#29], [d_date_sk#33], Inner

(56) CometProject
Input [4]: [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32, d_date_sk#33]
Arguments: [wr_return_quantity#28, i_item_id#32], [wr_return_quantity#28, i_item_id#32]

(57) CometHashAggregate
Input [2]: [wr_return_quantity#28, i_item_id#32]
Keys [1]: [i_item_id#32]
Functions [1]: [partial_sum(wr_return_quantity#28)]

(58) ColumnarToRow [codegen id : 4]
Input [2]: [i_item_id#32, sum#36]

(59) Exchange
Input [2]: [i_item_id#32, sum#36]
Arguments: hashpartitioning(i_item_id#32, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(60) HashAggregate [codegen id : 5]
Input [2]: [i_item_id#32, sum#36]
Keys [1]: [i_item_id#32]
Functions [1]: [sum(wr_return_quantity#28)]
Aggregate Attributes [1]: [sum(wr_return_quantity#28)#37]
Results [2]: [i_item_id#32 AS item_id#38, sum(wr_return_quantity#28)#37 AS wr_item_qty#39]

(61) BroadcastExchange
Input [2]: [item_id#38, wr_item_qty#39]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=5]

(62) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [item_id#12]
Right keys [1]: [item_id#38]
Join type: Inner
Join condition: None

(63) Project [codegen id : 6]
Output [8]: [item_id#12, sr_item_qty#13, (((cast(sr_item_qty#13 as double) / cast(((sr_item_qty#13 + cr_item_qty#26) + wr_item_qty#39) as double)) / 3.0) * 100.0) AS sr_dev#40, cr_item_qty#26, (((cast(cr_item_qty#26 as double) / cast(((sr_item_qty#13 + cr_item_qty#26) + wr_item_qty#39) as double)) / 3.0) * 100.0) AS cr_dev#41, wr_item_qty#39, (((cast(wr_item_qty#39 as double) / cast(((sr_item_qty#13 + cr_item_qty#26) + wr_item_qty#39) as double)) / 3.0) * 100.0) AS wr_dev#42, (cast(((sr_item_qty#13 + cr_item_qty#26) + wr_item_qty#39) as decimal(20,0)) / 3.0) AS average#43]
Input [5]: [item_id#12, sr_item_qty#13, cr_item_qty#26, item_id#38, wr_item_qty#39]

(64) TakeOrderedAndProject
Input [8]: [item_id#12, sr_item_qty#13, sr_dev#40, cr_item_qty#26, cr_dev#41, wr_item_qty#39, wr_dev#42, average#43]
Arguments: 100, [item_id#12 ASC NULLS FIRST, sr_item_qty#13 ASC NULLS FIRST], [item_id#12, sr_item_qty#13, sr_dev#40, cr_item_qty#26, cr_dev#41, wr_item_qty#39, wr_dev#42, average#43]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = sr_returned_date_sk#3 IN dynamicpruning#4
BroadcastExchange (78)
+- * ColumnarToRow (77)
   +- CometProject (76)
      +- CometBroadcastHashJoin (75)
         :- CometFilter (66)
         :  +- CometScan parquet spark_catalog.default.date_dim (65)
         +- CometBroadcastExchange (74)
            +- CometProject (73)
               +- CometBroadcastHashJoin (72)
                  :- CometScan parquet spark_catalog.default.date_dim (67)
                  +- CometBroadcastExchange (71)
                     +- CometProject (70)
                        +- CometFilter (69)
                           +- CometScan parquet spark_catalog.default.date_dim (68)


(65) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#7, d_date#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(66) CometFilter
Input [2]: [d_date_sk#7, d_date#8]
Condition : isnotnull(d_date_sk#7)

(67) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#9, d_week_seq#44]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(68) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#45, d_week_seq#46]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(69) CometFilter
Input [2]: [d_date#45, d_week_seq#46]
Condition : cast(d_date#45 as string) IN (2000-06-30,2000-09-27,2000-11-17)

(70) CometProject
Input [2]: [d_date#45, d_week_seq#46]
Arguments: [d_week_seq#46], [d_week_seq#46]

(71) CometBroadcastExchange
Input [1]: [d_week_seq#46]
Arguments: [d_week_seq#46]

(72) CometBroadcastHashJoin
Left output [2]: [d_date#9, d_week_seq#44]
Right output [1]: [d_week_seq#46]
Arguments: [d_week_seq#44], [d_week_seq#46], LeftSemi

(73) CometProject
Input [2]: [d_date#9, d_week_seq#44]
Arguments: [d_date#9], [d_date#9]

(74) CometBroadcastExchange
Input [1]: [d_date#9]
Arguments: [d_date#9]

(75) CometBroadcastHashJoin
Left output [2]: [d_date_sk#7, d_date#8]
Right output [1]: [d_date#9]
Arguments: [d_date#8], [d_date#9], LeftSemi

(76) CometProject
Input [2]: [d_date_sk#7, d_date#8]
Arguments: [d_date_sk#7], [d_date_sk#7]

(77) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#7]

(78) BroadcastExchange
Input [1]: [d_date_sk#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

Subquery:2 Hosting operator id = 20 Hosting Expression = cr_returned_date_sk#16 IN dynamicpruning#17
BroadcastExchange (92)
+- * ColumnarToRow (91)
   +- CometProject (90)
      +- CometBroadcastHashJoin (89)
         :- CometFilter (80)
         :  +- CometScan parquet spark_catalog.default.date_dim (79)
         +- CometBroadcastExchange (88)
            +- CometProject (87)
               +- CometBroadcastHashJoin (86)
                  :- CometScan parquet spark_catalog.default.date_dim (81)
                  +- CometBroadcastExchange (85)
                     +- CometProject (84)
                        +- CometFilter (83)
                           +- CometScan parquet spark_catalog.default.date_dim (82)


(79) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#20, d_date#21]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(80) CometFilter
Input [2]: [d_date_sk#20, d_date#21]
Condition : isnotnull(d_date_sk#20)

(81) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#22, d_week_seq#47]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(82) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#48, d_week_seq#49]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(83) CometFilter
Input [2]: [d_date#48, d_week_seq#49]
Condition : cast(d_date#48 as string) IN (2000-06-30,2000-09-27,2000-11-17)

(84) CometProject
Input [2]: [d_date#48, d_week_seq#49]
Arguments: [d_week_seq#49], [d_week_seq#49]

(85) CometBroadcastExchange
Input [1]: [d_week_seq#49]
Arguments: [d_week_seq#49]

(86) CometBroadcastHashJoin
Left output [2]: [d_date#22, d_week_seq#47]
Right output [1]: [d_week_seq#49]
Arguments: [d_week_seq#47], [d_week_seq#49], LeftSemi

(87) CometProject
Input [2]: [d_date#22, d_week_seq#47]
Arguments: [d_date#22], [d_date#22]

(88) CometBroadcastExchange
Input [1]: [d_date#22]
Arguments: [d_date#22]

(89) CometBroadcastHashJoin
Left output [2]: [d_date_sk#20, d_date#21]
Right output [1]: [d_date#22]
Arguments: [d_date#21], [d_date#22], LeftSemi

(90) CometProject
Input [2]: [d_date_sk#20, d_date#21]
Arguments: [d_date_sk#20], [d_date_sk#20]

(91) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#20]

(92) BroadcastExchange
Input [1]: [d_date_sk#20]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=7]

Subquery:3 Hosting operator id = 42 Hosting Expression = wr_returned_date_sk#29 IN dynamicpruning#30
BroadcastExchange (106)
+- * ColumnarToRow (105)
   +- CometProject (104)
      +- CometBroadcastHashJoin (103)
         :- CometFilter (94)
         :  +- CometScan parquet spark_catalog.default.date_dim (93)
         +- CometBroadcastExchange (102)
            +- CometProject (101)
               +- CometBroadcastHashJoin (100)
                  :- CometScan parquet spark_catalog.default.date_dim (95)
                  +- CometBroadcastExchange (99)
                     +- CometProject (98)
                        +- CometFilter (97)
                           +- CometScan parquet spark_catalog.default.date_dim (96)


(93) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#33, d_date#34]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(94) CometFilter
Input [2]: [d_date_sk#33, d_date#34]
Condition : isnotnull(d_date_sk#33)

(95) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#35, d_week_seq#50]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(96) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#51, d_week_seq#52]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(97) CometFilter
Input [2]: [d_date#51, d_week_seq#52]
Condition : cast(d_date#51 as string) IN (2000-06-30,2000-09-27,2000-11-17)

(98) CometProject
Input [2]: [d_date#51, d_week_seq#52]
Arguments: [d_week_seq#52], [d_week_seq#52]

(99) CometBroadcastExchange
Input [1]: [d_week_seq#52]
Arguments: [d_week_seq#52]

(100) CometBroadcastHashJoin
Left output [2]: [d_date#35, d_week_seq#50]
Right output [1]: [d_week_seq#52]
Arguments: [d_week_seq#50], [d_week_seq#52], LeftSemi

(101) CometProject
Input [2]: [d_date#35, d_week_seq#50]
Arguments: [d_date#35], [d_date#35]

(102) CometBroadcastExchange
Input [1]: [d_date#35]
Arguments: [d_date#35]

(103) CometBroadcastHashJoin
Left output [2]: [d_date_sk#33, d_date#34]
Right output [1]: [d_date#35]
Arguments: [d_date#34], [d_date#35], LeftSemi

(104) CometProject
Input [2]: [d_date_sk#33, d_date#34]
Arguments: [d_date_sk#33], [d_date_sk#33]

(105) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#33]

(106) BroadcastExchange
Input [1]: [d_date_sk#33]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]


