== Physical Plan ==
* HashAggregate (59)
+- Exchange (58)
   +- * HashAggregate (57)
      +- * Project (56)
         +- * BroadcastHashJoin LeftSemi BuildRight (55)
            :- * BroadcastHashJoin LeftSemi BuildRight (36)
            :  :- * HashAggregate (17)
            :  :  +- Exchange (16)
            :  :     +- * ColumnarToRow (15)
            :  :        +- CometHashAggregate (14)
            :  :           +- CometProject (13)
            :  :              +- CometBroadcastHashJoin (12)
            :  :                 :- CometProject (8)
            :  :                 :  +- CometBroadcastHashJoin (7)
            :  :                 :     :- CometFilter (2)
            :  :                 :     :  +- CometScan parquet spark_catalog.default.store_sales (1)
            :  :                 :     +- CometBroadcastExchange (6)
            :  :                 :        +- CometProject (5)
            :  :                 :           +- CometFilter (4)
            :  :                 :              +- CometScan parquet spark_catalog.default.date_dim (3)
            :  :                 +- CometBroadcastExchange (11)
            :  :                    +- CometFilter (10)
            :  :                       +- CometScan parquet spark_catalog.default.customer (9)
            :  +- BroadcastExchange (35)
            :     +- * HashAggregate (34)
            :        +- Exchange (33)
            :           +- * ColumnarToRow (32)
            :              +- CometHashAggregate (31)
            :                 +- CometProject (30)
            :                    +- CometBroadcastHashJoin (29)
            :                       :- CometProject (25)
            :                       :  +- CometBroadcastHashJoin (24)
            :                       :     :- CometFilter (19)
            :                       :     :  +- CometScan parquet spark_catalog.default.catalog_sales (18)
            :                       :     +- CometBroadcastExchange (23)
            :                       :        +- CometProject (22)
            :                       :           +- CometFilter (21)
            :                       :              +- CometScan parquet spark_catalog.default.date_dim (20)
            :                       +- CometBroadcastExchange (28)
            :                          +- CometFilter (27)
            :                             +- CometScan parquet spark_catalog.default.customer (26)
            +- BroadcastExchange (54)
               +- * HashAggregate (53)
                  +- Exchange (52)
                     +- * ColumnarToRow (51)
                        +- CometHashAggregate (50)
                           +- CometProject (49)
                              +- CometBroadcastHashJoin (48)
                                 :- CometProject (44)
                                 :  +- CometBroadcastHashJoin (43)
                                 :     :- CometFilter (38)
                                 :     :  +- CometScan parquet spark_catalog.default.web_sales (37)
                                 :     +- CometBroadcastExchange (42)
                                 :        +- CometProject (41)
                                 :           +- CometFilter (40)
                                 :              +- CometScan parquet spark_catalog.default.date_dim (39)
                                 +- CometBroadcastExchange (47)
                                    +- CometFilter (46)
                                       +- CometScan parquet spark_catalog.default.customer (45)


(1) Scan parquet spark_catalog.default.store_sales
Output [2]: [ss_customer_sk#1, ss_sold_date_sk#2]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#2), dynamicpruningexpression(ss_sold_date_sk#2 IN dynamicpruning#3)]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int>

(2) CometFilter
Input [2]: [ss_customer_sk#1, ss_sold_date_sk#2]
Condition : isnotnull(ss_customer_sk#1)

(3) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#4, d_date#5, d_month_seq#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_month_seq:int>

(4) CometFilter
Input [3]: [d_date_sk#4, d_date#5, d_month_seq#6]
Condition : (((isnotnull(d_month_seq#6) AND (d_month_seq#6 >= 1200)) AND (d_month_seq#6 <= 1211)) AND isnotnull(d_date_sk#4))

(5) CometProject
Input [3]: [d_date_sk#4, d_date#5, d_month_seq#6]
Arguments: [d_date_sk#4, d_date#5], [d_date_sk#4, d_date#5]

(6) CometBroadcastExchange
Input [2]: [d_date_sk#4, d_date#5]
Arguments: [d_date_sk#4, d_date#5]

(7) CometBroadcastHashJoin
Left output [2]: [ss_customer_sk#1, ss_sold_date_sk#2]
Right output [2]: [d_date_sk#4, d_date#5]
Arguments: [ss_sold_date_sk#2], [d_date_sk#4], Inner

(8) CometProject
Input [4]: [ss_customer_sk#1, ss_sold_date_sk#2, d_date_sk#4, d_date#5]
Arguments: [ss_customer_sk#1, d_date#5], [ss_customer_sk#1, d_date#5]

(9) Scan parquet spark_catalog.default.customer
Output [3]: [c_customer_sk#7, c_first_name#8, c_last_name#9]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>

(10) CometFilter
Input [3]: [c_customer_sk#7, c_first_name#8, c_last_name#9]
Condition : isnotnull(c_customer_sk#7)

(11) CometBroadcastExchange
Input [3]: [c_customer_sk#7, c_first_name#8, c_last_name#9]
Arguments: [c_customer_sk#7, c_first_name#8, c_last_name#9]

(12) CometBroadcastHashJoin
Left output [2]: [ss_customer_sk#1, d_date#5]
Right output [3]: [c_customer_sk#7, c_first_name#8, c_last_name#9]
Arguments: [ss_customer_sk#1], [c_customer_sk#7], Inner

(13) CometProject
Input [5]: [ss_customer_sk#1, d_date#5, c_customer_sk#7, c_first_name#8, c_last_name#9]
Arguments: [c_last_name#9, c_first_name#8, d_date#5], [c_last_name#9, c_first_name#8, d_date#5]

(14) CometHashAggregate
Input [3]: [c_last_name#9, c_first_name#8, d_date#5]
Keys [3]: [c_last_name#9, c_first_name#8, d_date#5]
Functions: []

(15) ColumnarToRow [codegen id : 1]
Input [3]: [c_last_name#9, c_first_name#8, d_date#5]

(16) Exchange
Input [3]: [c_last_name#9, c_first_name#8, d_date#5]
Arguments: hashpartitioning(c_last_name#9, c_first_name#8, d_date#5, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(17) HashAggregate [codegen id : 6]
Input [3]: [c_last_name#9, c_first_name#8, d_date#5]
Keys [3]: [c_last_name#9, c_first_name#8, d_date#5]
Functions: []
Aggregate Attributes: []
Results [3]: [c_last_name#9, c_first_name#8, d_date#5]

(18) Scan parquet spark_catalog.default.catalog_sales
Output [2]: [cs_bill_customer_sk#10, cs_sold_date_sk#11]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#11), dynamicpruningexpression(cs_sold_date_sk#11 IN dynamicpruning#12)]
PushedFilters: [IsNotNull(cs_bill_customer_sk)]
ReadSchema: struct<cs_bill_customer_sk:int>

(19) CometFilter
Input [2]: [cs_bill_customer_sk#10, cs_sold_date_sk#11]
Condition : isnotnull(cs_bill_customer_sk#10)

(20) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#13, d_date#14, d_month_seq#15]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_month_seq:int>

(21) CometFilter
Input [3]: [d_date_sk#13, d_date#14, d_month_seq#15]
Condition : (((isnotnull(d_month_seq#15) AND (d_month_seq#15 >= 1200)) AND (d_month_seq#15 <= 1211)) AND isnotnull(d_date_sk#13))

(22) CometProject
Input [3]: [d_date_sk#13, d_date#14, d_month_seq#15]
Arguments: [d_date_sk#13, d_date#14], [d_date_sk#13, d_date#14]

(23) CometBroadcastExchange
Input [2]: [d_date_sk#13, d_date#14]
Arguments: [d_date_sk#13, d_date#14]

(24) CometBroadcastHashJoin
Left output [2]: [cs_bill_customer_sk#10, cs_sold_date_sk#11]
Right output [2]: [d_date_sk#13, d_date#14]
Arguments: [cs_sold_date_sk#11], [d_date_sk#13], Inner

(25) CometProject
Input [4]: [cs_bill_customer_sk#10, cs_sold_date_sk#11, d_date_sk#13, d_date#14]
Arguments: [cs_bill_customer_sk#10, d_date#14], [cs_bill_customer_sk#10, d_date#14]

(26) Scan parquet spark_catalog.default.customer
Output [3]: [c_customer_sk#16, c_first_name#17, c_last_name#18]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>

(27) CometFilter
Input [3]: [c_customer_sk#16, c_first_name#17, c_last_name#18]
Condition : isnotnull(c_customer_sk#16)

(28) CometBroadcastExchange
Input [3]: [c_customer_sk#16, c_first_name#17, c_last_name#18]
Arguments: [c_customer_sk#16, c_first_name#17, c_last_name#18]

(29) CometBroadcastHashJoin
Left output [2]: [cs_bill_customer_sk#10, d_date#14]
Right output [3]: [c_customer_sk#16, c_first_name#17, c_last_name#18]
Arguments: [cs_bill_customer_sk#10], [c_customer_sk#16], Inner

(30) CometProject
Input [5]: [cs_bill_customer_sk#10, d_date#14, c_customer_sk#16, c_first_name#17, c_last_name#18]
Arguments: [c_last_name#18, c_first_name#17, d_date#14], [c_last_name#18, c_first_name#17, d_date#14]

(31) CometHashAggregate
Input [3]: [c_last_name#18, c_first_name#17, d_date#14]
Keys [3]: [c_last_name#18, c_first_name#17, d_date#14]
Functions: []

(32) ColumnarToRow [codegen id : 2]
Input [3]: [c_last_name#18, c_first_name#17, d_date#14]

(33) Exchange
Input [3]: [c_last_name#18, c_first_name#17, d_date#14]
Arguments: hashpartitioning(c_last_name#18, c_first_name#17, d_date#14, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(34) HashAggregate [codegen id : 3]
Input [3]: [c_last_name#18, c_first_name#17, d_date#14]
Keys [3]: [c_last_name#18, c_first_name#17, d_date#14]
Functions: []
Aggregate Attributes: []
Results [3]: [c_last_name#18, c_first_name#17, d_date#14]

(35) BroadcastExchange
Input [3]: [c_last_name#18, c_first_name#17, d_date#14]
Arguments: HashedRelationBroadcastMode(List(coalesce(input[0, string, true], ), isnull(input[0, string, true]), coalesce(input[1, string, true], ), isnull(input[1, string, true]), coalesce(input[2, date, true], 1970-01-01), isnull(input[2, date, true])),false), [plan_id=3]

(36) BroadcastHashJoin [codegen id : 6]
Left keys [6]: [coalesce(c_last_name#9, ), isnull(c_last_name#9), coalesce(c_first_name#8, ), isnull(c_first_name#8), coalesce(d_date#5, 1970-01-01), isnull(d_date#5)]
Right keys [6]: [coalesce(c_last_name#18, ), isnull(c_last_name#18), coalesce(c_first_name#17, ), isnull(c_first_name#17), coalesce(d_date#14, 1970-01-01), isnull(d_date#14)]
Join type: LeftSemi
Join condition: None

(37) Scan parquet spark_catalog.default.web_sales
Output [2]: [ws_bill_customer_sk#19, ws_sold_date_sk#20]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#20), dynamicpruningexpression(ws_sold_date_sk#20 IN dynamicpruning#21)]
PushedFilters: [IsNotNull(ws_bill_customer_sk)]
ReadSchema: struct<ws_bill_customer_sk:int>

(38) CometFilter
Input [2]: [ws_bill_customer_sk#19, ws_sold_date_sk#20]
Condition : isnotnull(ws_bill_customer_sk#19)

(39) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#22, d_date#23, d_month_seq#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_month_seq:int>

(40) CometFilter
Input [3]: [d_date_sk#22, d_date#23, d_month_seq#24]
Condition : (((isnotnull(d_month_seq#24) AND (d_month_seq#24 >= 1200)) AND (d_month_seq#24 <= 1211)) AND isnotnull(d_date_sk#22))

(41) CometProject
Input [3]: [d_date_sk#22, d_date#23, d_month_seq#24]
Arguments: [d_date_sk#22, d_date#23], [d_date_sk#22, d_date#23]

(42) CometBroadcastExchange
Input [2]: [d_date_sk#22, d_date#23]
Arguments: [d_date_sk#22, d_date#23]

(43) CometBroadcastHashJoin
Left output [2]: [ws_bill_customer_sk#19, ws_sold_date_sk#20]
Right output [2]: [d_date_sk#22, d_date#23]
Arguments: [ws_sold_date_sk#20], [d_date_sk#22], Inner

(44) CometProject
Input [4]: [ws_bill_customer_sk#19, ws_sold_date_sk#20, d_date_sk#22, d_date#23]
Arguments: [ws_bill_customer_sk#19, d_date#23], [ws_bill_customer_sk#19, d_date#23]

(45) Scan parquet spark_catalog.default.customer
Output [3]: [c_customer_sk#25, c_first_name#26, c_last_name#27]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>

(46) CometFilter
Input [3]: [c_customer_sk#25, c_first_name#26, c_last_name#27]
Condition : isnotnull(c_customer_sk#25)

(47) CometBroadcastExchange
Input [3]: [c_customer_sk#25, c_first_name#26, c_last_name#27]
Arguments: [c_customer_sk#25, c_first_name#26, c_last_name#27]

(48) CometBroadcastHashJoin
Left output [2]: [ws_bill_customer_sk#19, d_date#23]
Right output [3]: [c_customer_sk#25, c_first_name#26, c_last_name#27]
Arguments: [ws_bill_customer_sk#19], [c_customer_sk#25], Inner

(49) CometProject
Input [5]: [ws_bill_customer_sk#19, d_date#23, c_customer_sk#25, c_first_name#26, c_last_name#27]
Arguments: [c_last_name#27, c_first_name#26, d_date#23], [c_last_name#27, c_first_name#26, d_date#23]

(50) CometHashAggregate
Input [3]: [c_last_name#27, c_first_name#26, d_date#23]
Keys [3]: [c_last_name#27, c_first_name#26, d_date#23]
Functions: []

(51) ColumnarToRow [codegen id : 4]
Input [3]: [c_last_name#27, c_first_name#26, d_date#23]

(52) Exchange
Input [3]: [c_last_name#27, c_first_name#26, d_date#23]
Arguments: hashpartitioning(c_last_name#27, c_first_name#26, d_date#23, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(53) HashAggregate [codegen id : 5]
Input [3]: [c_last_name#27, c_first_name#26, d_date#23]
Keys [3]: [c_last_name#27, c_first_name#26, d_date#23]
Functions: []
Aggregate Attributes: []
Results [3]: [c_last_name#27, c_first_name#26, d_date#23]

(54) BroadcastExchange
Input [3]: [c_last_name#27, c_first_name#26, d_date#23]
Arguments: HashedRelationBroadcastMode(List(coalesce(input[0, string, true], ), isnull(input[0, string, true]), coalesce(input[1, string, true], ), isnull(input[1, string, true]), coalesce(input[2, date, true], 1970-01-01), isnull(input[2, date, true])),false), [plan_id=5]

(55) BroadcastHashJoin [codegen id : 6]
Left keys [6]: [coalesce(c_last_name#9, ), isnull(c_last_name#9), coalesce(c_first_name#8, ), isnull(c_first_name#8), coalesce(d_date#5, 1970-01-01), isnull(d_date#5)]
Right keys [6]: [coalesce(c_last_name#27, ), isnull(c_last_name#27), coalesce(c_first_name#26, ), isnull(c_first_name#26), coalesce(d_date#23, 1970-01-01), isnull(d_date#23)]
Join type: LeftSemi
Join condition: None

(56) Project [codegen id : 6]
Output: []
Input [3]: [c_last_name#9, c_first_name#8, d_date#5]

(57) HashAggregate [codegen id : 6]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#28]
Results [1]: [count#29]

(58) Exchange
Input [1]: [count#29]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(59) HashAggregate [codegen id : 7]
Input [1]: [count#29]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#30]
Results [1]: [count(1)#30 AS count(1)#31]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#2 IN dynamicpruning#3
BroadcastExchange (64)
+- * ColumnarToRow (63)
   +- CometProject (62)
      +- CometFilter (61)
         +- CometScan parquet spark_catalog.default.date_dim (60)


(60) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#4, d_date#5, d_month_seq#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_month_seq:int>

(61) CometFilter
Input [3]: [d_date_sk#4, d_date#5, d_month_seq#6]
Condition : (((isnotnull(d_month_seq#6) AND (d_month_seq#6 >= 1200)) AND (d_month_seq#6 <= 1211)) AND isnotnull(d_date_sk#4))

(62) CometProject
Input [3]: [d_date_sk#4, d_date#5, d_month_seq#6]
Arguments: [d_date_sk#4, d_date#5], [d_date_sk#4, d_date#5]

(63) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#4, d_date#5]

(64) BroadcastExchange
Input [2]: [d_date_sk#4, d_date#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=7]

Subquery:2 Hosting operator id = 18 Hosting Expression = cs_sold_date_sk#11 IN dynamicpruning#3

Subquery:3 Hosting operator id = 37 Hosting Expression = ws_sold_date_sk#20 IN dynamicpruning#3


