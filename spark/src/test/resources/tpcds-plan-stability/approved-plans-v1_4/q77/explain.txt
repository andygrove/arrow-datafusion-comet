== Physical Plan ==
TakeOrderedAndProject (105)
+- * HashAggregate (104)
   +- Exchange (103)
      +- * HashAggregate (102)
         +- * Expand (101)
            +- Union (100)
               :- * Project (37)
               :  +- * BroadcastHashJoin LeftOuter BuildRight (36)
               :     :- * HashAggregate (17)
               :     :  +- Exchange (16)
               :     :     +- * ColumnarToRow (15)
               :     :        +- CometHashAggregate (14)
               :     :           +- CometProject (13)
               :     :              +- CometBroadcastHashJoin (12)
               :     :                 :- CometProject (8)
               :     :                 :  +- CometBroadcastHashJoin (7)
               :     :                 :     :- CometFilter (2)
               :     :                 :     :  +- CometScan parquet spark_catalog.default.store_sales (1)
               :     :                 :     +- CometBroadcastExchange (6)
               :     :                 :        +- CometProject (5)
               :     :                 :           +- CometFilter (4)
               :     :                 :              +- CometScan parquet spark_catalog.default.date_dim (3)
               :     :                 +- CometBroadcastExchange (11)
               :     :                    +- CometFilter (10)
               :     :                       +- CometScan parquet spark_catalog.default.store (9)
               :     +- BroadcastExchange (35)
               :        +- * HashAggregate (34)
               :           +- Exchange (33)
               :              +- * ColumnarToRow (32)
               :                 +- CometHashAggregate (31)
               :                    +- CometProject (30)
               :                       +- CometBroadcastHashJoin (29)
               :                          :- CometProject (25)
               :                          :  +- CometBroadcastHashJoin (24)
               :                          :     :- CometFilter (19)
               :                          :     :  +- CometScan parquet spark_catalog.default.store_returns (18)
               :                          :     +- CometBroadcastExchange (23)
               :                          :        +- CometProject (22)
               :                          :           +- CometFilter (21)
               :                          :              +- CometScan parquet spark_catalog.default.date_dim (20)
               :                          +- CometBroadcastExchange (28)
               :                             +- CometFilter (27)
               :                                +- CometScan parquet spark_catalog.default.store (26)
               :- * Project (62)
               :  +- * BroadcastNestedLoopJoin Inner BuildLeft (61)
               :     :- BroadcastExchange (49)
               :     :  +- * HashAggregate (48)
               :     :     +- Exchange (47)
               :     :        +- * ColumnarToRow (46)
               :     :           +- CometHashAggregate (45)
               :     :              +- CometProject (44)
               :     :                 +- CometBroadcastHashJoin (43)
               :     :                    :- CometScan parquet spark_catalog.default.catalog_sales (38)
               :     :                    +- CometBroadcastExchange (42)
               :     :                       +- CometProject (41)
               :     :                          +- CometFilter (40)
               :     :                             +- CometScan parquet spark_catalog.default.date_dim (39)
               :     +- * HashAggregate (60)
               :        +- Exchange (59)
               :           +- * ColumnarToRow (58)
               :              +- CometHashAggregate (57)
               :                 +- CometProject (56)
               :                    +- CometBroadcastHashJoin (55)
               :                       :- CometScan parquet spark_catalog.default.catalog_returns (50)
               :                       +- CometBroadcastExchange (54)
               :                          +- CometProject (53)
               :                             +- CometFilter (52)
               :                                +- CometScan parquet spark_catalog.default.date_dim (51)
               +- * Project (99)
                  +- * BroadcastHashJoin LeftOuter BuildRight (98)
                     :- * HashAggregate (79)
                     :  +- Exchange (78)
                     :     +- * ColumnarToRow (77)
                     :        +- CometHashAggregate (76)
                     :           +- CometProject (75)
                     :              +- CometBroadcastHashJoin (74)
                     :                 :- CometProject (70)
                     :                 :  +- CometBroadcastHashJoin (69)
                     :                 :     :- CometFilter (64)
                     :                 :     :  +- CometScan parquet spark_catalog.default.web_sales (63)
                     :                 :     +- CometBroadcastExchange (68)
                     :                 :        +- CometProject (67)
                     :                 :           +- CometFilter (66)
                     :                 :              +- CometScan parquet spark_catalog.default.date_dim (65)
                     :                 +- CometBroadcastExchange (73)
                     :                    +- CometFilter (72)
                     :                       +- CometScan parquet spark_catalog.default.web_page (71)
                     +- BroadcastExchange (97)
                        +- * HashAggregate (96)
                           +- Exchange (95)
                              +- * ColumnarToRow (94)
                                 +- CometHashAggregate (93)
                                    +- CometProject (92)
                                       +- CometBroadcastHashJoin (91)
                                          :- CometProject (87)
                                          :  +- CometBroadcastHashJoin (86)
                                          :     :- CometFilter (81)
                                          :     :  +- CometScan parquet spark_catalog.default.web_returns (80)
                                          :     +- CometBroadcastExchange (85)
                                          :        +- CometProject (84)
                                          :           +- CometFilter (83)
                                          :              +- CometScan parquet spark_catalog.default.date_dim (82)
                                          +- CometBroadcastExchange (90)
                                             +- CometFilter (89)
                                                +- CometScan parquet spark_catalog.default.web_page (88)


(1) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#4), dynamicpruningexpression(ss_sold_date_sk#4 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_store_sk:int,ss_ext_sales_price:decimal(7,2),ss_net_profit:decimal(7,2)>

(2) CometFilter
Input [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Condition : isnotnull(ss_store_sk#1)

(3) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#6, d_date#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-03), LessThanOrEqual(d_date,2000-09-02), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(4) CometFilter
Input [2]: [d_date_sk#6, d_date#7]
Condition : (((isnotnull(d_date#7) AND (d_date#7 >= 2000-08-03)) AND (d_date#7 <= 2000-09-02)) AND isnotnull(d_date_sk#6))

(5) CometProject
Input [2]: [d_date_sk#6, d_date#7]
Arguments: [d_date_sk#6], [d_date_sk#6]

(6) CometBroadcastExchange
Input [1]: [d_date_sk#6]
Arguments: [d_date_sk#6]

(7) CometBroadcastHashJoin
Left output [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Right output [1]: [d_date_sk#6]
Arguments: [ss_sold_date_sk#4], [d_date_sk#6], Inner

(8) CometProject
Input [5]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4, d_date_sk#6]
Arguments: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3], [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3]

(9) Scan parquet spark_catalog.default.store
Output [1]: [s_store_sk#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int>

(10) CometFilter
Input [1]: [s_store_sk#8]
Condition : isnotnull(s_store_sk#8)

(11) CometBroadcastExchange
Input [1]: [s_store_sk#8]
Arguments: [s_store_sk#8]

(12) CometBroadcastHashJoin
Left output [3]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3]
Right output [1]: [s_store_sk#8]
Arguments: [ss_store_sk#1], [s_store_sk#8], Inner

(13) CometProject
Input [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, s_store_sk#8]
Arguments: [ss_ext_sales_price#2, ss_net_profit#3, s_store_sk#8], [ss_ext_sales_price#2, ss_net_profit#3, s_store_sk#8]

(14) CometHashAggregate
Input [3]: [ss_ext_sales_price#2, ss_net_profit#3, s_store_sk#8]
Keys [1]: [s_store_sk#8]
Functions [2]: [partial_sum(UnscaledValue(ss_ext_sales_price#2)), partial_sum(UnscaledValue(ss_net_profit#3))]

(15) ColumnarToRow [codegen id : 1]
Input [3]: [s_store_sk#8, sum#9, sum#10]

(16) Exchange
Input [3]: [s_store_sk#8, sum#9, sum#10]
Arguments: hashpartitioning(s_store_sk#8, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(17) HashAggregate [codegen id : 4]
Input [3]: [s_store_sk#8, sum#9, sum#10]
Keys [1]: [s_store_sk#8]
Functions [2]: [sum(UnscaledValue(ss_ext_sales_price#2)), sum(UnscaledValue(ss_net_profit#3))]
Aggregate Attributes [2]: [sum(UnscaledValue(ss_ext_sales_price#2))#11, sum(UnscaledValue(ss_net_profit#3))#12]
Results [3]: [s_store_sk#8, MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#2))#11,17,2) AS sales#13, MakeDecimal(sum(UnscaledValue(ss_net_profit#3))#12,17,2) AS profit#14]

(18) Scan parquet spark_catalog.default.store_returns
Output [4]: [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17, sr_returned_date_sk#18]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(sr_returned_date_sk#18), dynamicpruningexpression(sr_returned_date_sk#18 IN dynamicpruning#19)]
PushedFilters: [IsNotNull(sr_store_sk)]
ReadSchema: struct<sr_store_sk:int,sr_return_amt:decimal(7,2),sr_net_loss:decimal(7,2)>

(19) CometFilter
Input [4]: [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17, sr_returned_date_sk#18]
Condition : isnotnull(sr_store_sk#15)

(20) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#20, d_date#21]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-03), LessThanOrEqual(d_date,2000-09-02), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(21) CometFilter
Input [2]: [d_date_sk#20, d_date#21]
Condition : (((isnotnull(d_date#21) AND (d_date#21 >= 2000-08-03)) AND (d_date#21 <= 2000-09-02)) AND isnotnull(d_date_sk#20))

(22) CometProject
Input [2]: [d_date_sk#20, d_date#21]
Arguments: [d_date_sk#20], [d_date_sk#20]

(23) CometBroadcastExchange
Input [1]: [d_date_sk#20]
Arguments: [d_date_sk#20]

(24) CometBroadcastHashJoin
Left output [4]: [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17, sr_returned_date_sk#18]
Right output [1]: [d_date_sk#20]
Arguments: [sr_returned_date_sk#18], [d_date_sk#20], Inner

(25) CometProject
Input [5]: [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17, sr_returned_date_sk#18, d_date_sk#20]
Arguments: [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17], [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17]

(26) Scan parquet spark_catalog.default.store
Output [1]: [s_store_sk#22]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int>

(27) CometFilter
Input [1]: [s_store_sk#22]
Condition : isnotnull(s_store_sk#22)

(28) CometBroadcastExchange
Input [1]: [s_store_sk#22]
Arguments: [s_store_sk#22]

(29) CometBroadcastHashJoin
Left output [3]: [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17]
Right output [1]: [s_store_sk#22]
Arguments: [sr_store_sk#15], [s_store_sk#22], Inner

(30) CometProject
Input [4]: [sr_store_sk#15, sr_return_amt#16, sr_net_loss#17, s_store_sk#22]
Arguments: [sr_return_amt#16, sr_net_loss#17, s_store_sk#22], [sr_return_amt#16, sr_net_loss#17, s_store_sk#22]

(31) CometHashAggregate
Input [3]: [sr_return_amt#16, sr_net_loss#17, s_store_sk#22]
Keys [1]: [s_store_sk#22]
Functions [2]: [partial_sum(UnscaledValue(sr_return_amt#16)), partial_sum(UnscaledValue(sr_net_loss#17))]

(32) ColumnarToRow [codegen id : 2]
Input [3]: [s_store_sk#22, sum#23, sum#24]

(33) Exchange
Input [3]: [s_store_sk#22, sum#23, sum#24]
Arguments: hashpartitioning(s_store_sk#22, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(34) HashAggregate [codegen id : 3]
Input [3]: [s_store_sk#22, sum#23, sum#24]
Keys [1]: [s_store_sk#22]
Functions [2]: [sum(UnscaledValue(sr_return_amt#16)), sum(UnscaledValue(sr_net_loss#17))]
Aggregate Attributes [2]: [sum(UnscaledValue(sr_return_amt#16))#25, sum(UnscaledValue(sr_net_loss#17))#26]
Results [3]: [s_store_sk#22, MakeDecimal(sum(UnscaledValue(sr_return_amt#16))#25,17,2) AS returns#27, MakeDecimal(sum(UnscaledValue(sr_net_loss#17))#26,17,2) AS profit_loss#28]

(35) BroadcastExchange
Input [3]: [s_store_sk#22, returns#27, profit_loss#28]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(36) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [s_store_sk#8]
Right keys [1]: [s_store_sk#22]
Join type: LeftOuter
Join condition: None

(37) Project [codegen id : 4]
Output [5]: [sales#13, coalesce(returns#27, 0.00) AS returns#29, (profit#14 - coalesce(profit_loss#28, 0.00)) AS profit#30, store channel AS channel#31, s_store_sk#8 AS id#32]
Input [6]: [s_store_sk#8, sales#13, profit#14, s_store_sk#22, returns#27, profit_loss#28]

(38) Scan parquet spark_catalog.default.catalog_sales
Output [4]: [cs_call_center_sk#33, cs_ext_sales_price#34, cs_net_profit#35, cs_sold_date_sk#36]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#36), dynamicpruningexpression(cs_sold_date_sk#36 IN dynamicpruning#37)]
ReadSchema: struct<cs_call_center_sk:int,cs_ext_sales_price:decimal(7,2),cs_net_profit:decimal(7,2)>

(39) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#38, d_date#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-03), LessThanOrEqual(d_date,2000-09-02), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(40) CometFilter
Input [2]: [d_date_sk#38, d_date#39]
Condition : (((isnotnull(d_date#39) AND (d_date#39 >= 2000-08-03)) AND (d_date#39 <= 2000-09-02)) AND isnotnull(d_date_sk#38))

(41) CometProject
Input [2]: [d_date_sk#38, d_date#39]
Arguments: [d_date_sk#38], [d_date_sk#38]

(42) CometBroadcastExchange
Input [1]: [d_date_sk#38]
Arguments: [d_date_sk#38]

(43) CometBroadcastHashJoin
Left output [4]: [cs_call_center_sk#33, cs_ext_sales_price#34, cs_net_profit#35, cs_sold_date_sk#36]
Right output [1]: [d_date_sk#38]
Arguments: [cs_sold_date_sk#36], [d_date_sk#38], Inner

(44) CometProject
Input [5]: [cs_call_center_sk#33, cs_ext_sales_price#34, cs_net_profit#35, cs_sold_date_sk#36, d_date_sk#38]
Arguments: [cs_call_center_sk#33, cs_ext_sales_price#34, cs_net_profit#35], [cs_call_center_sk#33, cs_ext_sales_price#34, cs_net_profit#35]

(45) CometHashAggregate
Input [3]: [cs_call_center_sk#33, cs_ext_sales_price#34, cs_net_profit#35]
Keys [1]: [cs_call_center_sk#33]
Functions [2]: [partial_sum(UnscaledValue(cs_ext_sales_price#34)), partial_sum(UnscaledValue(cs_net_profit#35))]

(46) ColumnarToRow [codegen id : 5]
Input [3]: [cs_call_center_sk#33, sum#40, sum#41]

(47) Exchange
Input [3]: [cs_call_center_sk#33, sum#40, sum#41]
Arguments: hashpartitioning(cs_call_center_sk#33, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(48) HashAggregate [codegen id : 6]
Input [3]: [cs_call_center_sk#33, sum#40, sum#41]
Keys [1]: [cs_call_center_sk#33]
Functions [2]: [sum(UnscaledValue(cs_ext_sales_price#34)), sum(UnscaledValue(cs_net_profit#35))]
Aggregate Attributes [2]: [sum(UnscaledValue(cs_ext_sales_price#34))#42, sum(UnscaledValue(cs_net_profit#35))#43]
Results [3]: [cs_call_center_sk#33, MakeDecimal(sum(UnscaledValue(cs_ext_sales_price#34))#42,17,2) AS sales#44, MakeDecimal(sum(UnscaledValue(cs_net_profit#35))#43,17,2) AS profit#45]

(49) BroadcastExchange
Input [3]: [cs_call_center_sk#33, sales#44, profit#45]
Arguments: IdentityBroadcastMode, [plan_id=5]

(50) Scan parquet spark_catalog.default.catalog_returns
Output [3]: [cr_return_amount#46, cr_net_loss#47, cr_returned_date_sk#48]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cr_returned_date_sk#48), dynamicpruningexpression(cr_returned_date_sk#48 IN dynamicpruning#49)]
ReadSchema: struct<cr_return_amount:decimal(7,2),cr_net_loss:decimal(7,2)>

(51) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#50, d_date#51]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-03), LessThanOrEqual(d_date,2000-09-02), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(52) CometFilter
Input [2]: [d_date_sk#50, d_date#51]
Condition : (((isnotnull(d_date#51) AND (d_date#51 >= 2000-08-03)) AND (d_date#51 <= 2000-09-02)) AND isnotnull(d_date_sk#50))

(53) CometProject
Input [2]: [d_date_sk#50, d_date#51]
Arguments: [d_date_sk#50], [d_date_sk#50]

(54) CometBroadcastExchange
Input [1]: [d_date_sk#50]
Arguments: [d_date_sk#50]

(55) CometBroadcastHashJoin
Left output [3]: [cr_return_amount#46, cr_net_loss#47, cr_returned_date_sk#48]
Right output [1]: [d_date_sk#50]
Arguments: [cr_returned_date_sk#48], [d_date_sk#50], Inner

(56) CometProject
Input [4]: [cr_return_amount#46, cr_net_loss#47, cr_returned_date_sk#48, d_date_sk#50]
Arguments: [cr_return_amount#46, cr_net_loss#47], [cr_return_amount#46, cr_net_loss#47]

(57) CometHashAggregate
Input [2]: [cr_return_amount#46, cr_net_loss#47]
Keys: []
Functions [2]: [partial_sum(UnscaledValue(cr_return_amount#46)), partial_sum(UnscaledValue(cr_net_loss#47))]

(58) ColumnarToRow [codegen id : 7]
Input [2]: [sum#52, sum#53]

(59) Exchange
Input [2]: [sum#52, sum#53]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(60) HashAggregate
Input [2]: [sum#52, sum#53]
Keys: []
Functions [2]: [sum(UnscaledValue(cr_return_amount#46)), sum(UnscaledValue(cr_net_loss#47))]
Aggregate Attributes [2]: [sum(UnscaledValue(cr_return_amount#46))#54, sum(UnscaledValue(cr_net_loss#47))#55]
Results [2]: [MakeDecimal(sum(UnscaledValue(cr_return_amount#46))#54,17,2) AS returns#56, MakeDecimal(sum(UnscaledValue(cr_net_loss#47))#55,17,2) AS profit_loss#57]

(61) BroadcastNestedLoopJoin [codegen id : 8]
Join type: Inner
Join condition: None

(62) Project [codegen id : 8]
Output [5]: [sales#44, returns#56, (profit#45 - profit_loss#57) AS profit#58, catalog channel AS channel#59, cs_call_center_sk#33 AS id#60]
Input [5]: [cs_call_center_sk#33, sales#44, profit#45, returns#56, profit_loss#57]

(63) Scan parquet spark_catalog.default.web_sales
Output [4]: [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63, ws_sold_date_sk#64]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#64), dynamicpruningexpression(ws_sold_date_sk#64 IN dynamicpruning#65)]
PushedFilters: [IsNotNull(ws_web_page_sk)]
ReadSchema: struct<ws_web_page_sk:int,ws_ext_sales_price:decimal(7,2),ws_net_profit:decimal(7,2)>

(64) CometFilter
Input [4]: [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63, ws_sold_date_sk#64]
Condition : isnotnull(ws_web_page_sk#61)

(65) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#66, d_date#67]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-03), LessThanOrEqual(d_date,2000-09-02), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(66) CometFilter
Input [2]: [d_date_sk#66, d_date#67]
Condition : (((isnotnull(d_date#67) AND (d_date#67 >= 2000-08-03)) AND (d_date#67 <= 2000-09-02)) AND isnotnull(d_date_sk#66))

(67) CometProject
Input [2]: [d_date_sk#66, d_date#67]
Arguments: [d_date_sk#66], [d_date_sk#66]

(68) CometBroadcastExchange
Input [1]: [d_date_sk#66]
Arguments: [d_date_sk#66]

(69) CometBroadcastHashJoin
Left output [4]: [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63, ws_sold_date_sk#64]
Right output [1]: [d_date_sk#66]
Arguments: [ws_sold_date_sk#64], [d_date_sk#66], Inner

(70) CometProject
Input [5]: [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63, ws_sold_date_sk#64, d_date_sk#66]
Arguments: [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63], [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63]

(71) Scan parquet spark_catalog.default.web_page
Output [1]: [wp_web_page_sk#68]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_page]
PushedFilters: [IsNotNull(wp_web_page_sk)]
ReadSchema: struct<wp_web_page_sk:int>

(72) CometFilter
Input [1]: [wp_web_page_sk#68]
Condition : isnotnull(wp_web_page_sk#68)

(73) CometBroadcastExchange
Input [1]: [wp_web_page_sk#68]
Arguments: [wp_web_page_sk#68]

(74) CometBroadcastHashJoin
Left output [3]: [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63]
Right output [1]: [wp_web_page_sk#68]
Arguments: [ws_web_page_sk#61], [wp_web_page_sk#68], Inner

(75) CometProject
Input [4]: [ws_web_page_sk#61, ws_ext_sales_price#62, ws_net_profit#63, wp_web_page_sk#68]
Arguments: [ws_ext_sales_price#62, ws_net_profit#63, wp_web_page_sk#68], [ws_ext_sales_price#62, ws_net_profit#63, wp_web_page_sk#68]

(76) CometHashAggregate
Input [3]: [ws_ext_sales_price#62, ws_net_profit#63, wp_web_page_sk#68]
Keys [1]: [wp_web_page_sk#68]
Functions [2]: [partial_sum(UnscaledValue(ws_ext_sales_price#62)), partial_sum(UnscaledValue(ws_net_profit#63))]

(77) ColumnarToRow [codegen id : 9]
Input [3]: [wp_web_page_sk#68, sum#69, sum#70]

(78) Exchange
Input [3]: [wp_web_page_sk#68, sum#69, sum#70]
Arguments: hashpartitioning(wp_web_page_sk#68, 5), ENSURE_REQUIREMENTS, [plan_id=7]

(79) HashAggregate [codegen id : 12]
Input [3]: [wp_web_page_sk#68, sum#69, sum#70]
Keys [1]: [wp_web_page_sk#68]
Functions [2]: [sum(UnscaledValue(ws_ext_sales_price#62)), sum(UnscaledValue(ws_net_profit#63))]
Aggregate Attributes [2]: [sum(UnscaledValue(ws_ext_sales_price#62))#71, sum(UnscaledValue(ws_net_profit#63))#72]
Results [3]: [wp_web_page_sk#68, MakeDecimal(sum(UnscaledValue(ws_ext_sales_price#62))#71,17,2) AS sales#73, MakeDecimal(sum(UnscaledValue(ws_net_profit#63))#72,17,2) AS profit#74]

(80) Scan parquet spark_catalog.default.web_returns
Output [4]: [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77, wr_returned_date_sk#78]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(wr_returned_date_sk#78), dynamicpruningexpression(wr_returned_date_sk#78 IN dynamicpruning#79)]
PushedFilters: [IsNotNull(wr_web_page_sk)]
ReadSchema: struct<wr_web_page_sk:int,wr_return_amt:decimal(7,2),wr_net_loss:decimal(7,2)>

(81) CometFilter
Input [4]: [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77, wr_returned_date_sk#78]
Condition : isnotnull(wr_web_page_sk#75)

(82) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#80, d_date#81]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-03), LessThanOrEqual(d_date,2000-09-02), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(83) CometFilter
Input [2]: [d_date_sk#80, d_date#81]
Condition : (((isnotnull(d_date#81) AND (d_date#81 >= 2000-08-03)) AND (d_date#81 <= 2000-09-02)) AND isnotnull(d_date_sk#80))

(84) CometProject
Input [2]: [d_date_sk#80, d_date#81]
Arguments: [d_date_sk#80], [d_date_sk#80]

(85) CometBroadcastExchange
Input [1]: [d_date_sk#80]
Arguments: [d_date_sk#80]

(86) CometBroadcastHashJoin
Left output [4]: [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77, wr_returned_date_sk#78]
Right output [1]: [d_date_sk#80]
Arguments: [wr_returned_date_sk#78], [d_date_sk#80], Inner

(87) CometProject
Input [5]: [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77, wr_returned_date_sk#78, d_date_sk#80]
Arguments: [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77], [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77]

(88) Scan parquet spark_catalog.default.web_page
Output [1]: [wp_web_page_sk#82]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_page]
PushedFilters: [IsNotNull(wp_web_page_sk)]
ReadSchema: struct<wp_web_page_sk:int>

(89) CometFilter
Input [1]: [wp_web_page_sk#82]
Condition : isnotnull(wp_web_page_sk#82)

(90) CometBroadcastExchange
Input [1]: [wp_web_page_sk#82]
Arguments: [wp_web_page_sk#82]

(91) CometBroadcastHashJoin
Left output [3]: [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77]
Right output [1]: [wp_web_page_sk#82]
Arguments: [wr_web_page_sk#75], [wp_web_page_sk#82], Inner

(92) CometProject
Input [4]: [wr_web_page_sk#75, wr_return_amt#76, wr_net_loss#77, wp_web_page_sk#82]
Arguments: [wr_return_amt#76, wr_net_loss#77, wp_web_page_sk#82], [wr_return_amt#76, wr_net_loss#77, wp_web_page_sk#82]

(93) CometHashAggregate
Input [3]: [wr_return_amt#76, wr_net_loss#77, wp_web_page_sk#82]
Keys [1]: [wp_web_page_sk#82]
Functions [2]: [partial_sum(UnscaledValue(wr_return_amt#76)), partial_sum(UnscaledValue(wr_net_loss#77))]

(94) ColumnarToRow [codegen id : 10]
Input [3]: [wp_web_page_sk#82, sum#83, sum#84]

(95) Exchange
Input [3]: [wp_web_page_sk#82, sum#83, sum#84]
Arguments: hashpartitioning(wp_web_page_sk#82, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(96) HashAggregate [codegen id : 11]
Input [3]: [wp_web_page_sk#82, sum#83, sum#84]
Keys [1]: [wp_web_page_sk#82]
Functions [2]: [sum(UnscaledValue(wr_return_amt#76)), sum(UnscaledValue(wr_net_loss#77))]
Aggregate Attributes [2]: [sum(UnscaledValue(wr_return_amt#76))#85, sum(UnscaledValue(wr_net_loss#77))#86]
Results [3]: [wp_web_page_sk#82, MakeDecimal(sum(UnscaledValue(wr_return_amt#76))#85,17,2) AS returns#87, MakeDecimal(sum(UnscaledValue(wr_net_loss#77))#86,17,2) AS profit_loss#88]

(97) BroadcastExchange
Input [3]: [wp_web_page_sk#82, returns#87, profit_loss#88]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=9]

(98) BroadcastHashJoin [codegen id : 12]
Left keys [1]: [wp_web_page_sk#68]
Right keys [1]: [wp_web_page_sk#82]
Join type: LeftOuter
Join condition: None

(99) Project [codegen id : 12]
Output [5]: [sales#73, coalesce(returns#87, 0.00) AS returns#89, (profit#74 - coalesce(profit_loss#88, 0.00)) AS profit#90, web channel AS channel#91, wp_web_page_sk#68 AS id#92]
Input [6]: [wp_web_page_sk#68, sales#73, profit#74, wp_web_page_sk#82, returns#87, profit_loss#88]

(100) Union

(101) Expand [codegen id : 13]
Input [5]: [sales#13, returns#29, profit#30, channel#31, id#32]
Arguments: [[sales#13, returns#29, profit#30, channel#31, id#32, 0], [sales#13, returns#29, profit#30, channel#31, null, 1], [sales#13, returns#29, profit#30, null, null, 3]], [sales#13, returns#29, profit#30, channel#93, id#94, spark_grouping_id#95]

(102) HashAggregate [codegen id : 13]
Input [6]: [sales#13, returns#29, profit#30, channel#93, id#94, spark_grouping_id#95]
Keys [3]: [channel#93, id#94, spark_grouping_id#95]
Functions [3]: [partial_sum(sales#13), partial_sum(returns#29), partial_sum(profit#30)]
Aggregate Attributes [6]: [sum#96, isEmpty#97, sum#98, isEmpty#99, sum#100, isEmpty#101]
Results [9]: [channel#93, id#94, spark_grouping_id#95, sum#102, isEmpty#103, sum#104, isEmpty#105, sum#106, isEmpty#107]

(103) Exchange
Input [9]: [channel#93, id#94, spark_grouping_id#95, sum#102, isEmpty#103, sum#104, isEmpty#105, sum#106, isEmpty#107]
Arguments: hashpartitioning(channel#93, id#94, spark_grouping_id#95, 5), ENSURE_REQUIREMENTS, [plan_id=10]

(104) HashAggregate [codegen id : 14]
Input [9]: [channel#93, id#94, spark_grouping_id#95, sum#102, isEmpty#103, sum#104, isEmpty#105, sum#106, isEmpty#107]
Keys [3]: [channel#93, id#94, spark_grouping_id#95]
Functions [3]: [sum(sales#13), sum(returns#29), sum(profit#30)]
Aggregate Attributes [3]: [sum(sales#13)#108, sum(returns#29)#109, sum(profit#30)#110]
Results [5]: [channel#93, id#94, sum(sales#13)#108 AS sales#111, sum(returns#29)#109 AS returns#112, sum(profit#30)#110 AS profit#113]

(105) TakeOrderedAndProject
Input [5]: [channel#93, id#94, sales#111, returns#112, profit#113]
Arguments: 100, [channel#93 ASC NULLS FIRST, id#94 ASC NULLS FIRST], [channel#93, id#94, sales#111, returns#112, profit#113]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#4 IN dynamicpruning#5
BroadcastExchange (110)
+- * ColumnarToRow (109)
   +- CometProject (108)
      +- CometFilter (107)
         +- CometScan parquet spark_catalog.default.date_dim (106)


(106) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#6, d_date#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-03), LessThanOrEqual(d_date,2000-09-02), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(107) CometFilter
Input [2]: [d_date_sk#6, d_date#7]
Condition : (((isnotnull(d_date#7) AND (d_date#7 >= 2000-08-03)) AND (d_date#7 <= 2000-09-02)) AND isnotnull(d_date_sk#6))

(108) CometProject
Input [2]: [d_date_sk#6, d_date#7]
Arguments: [d_date_sk#6], [d_date_sk#6]

(109) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#6]

(110) BroadcastExchange
Input [1]: [d_date_sk#6]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=11]

Subquery:2 Hosting operator id = 18 Hosting Expression = sr_returned_date_sk#18 IN dynamicpruning#5

Subquery:3 Hosting operator id = 38 Hosting Expression = cs_sold_date_sk#36 IN dynamicpruning#5

Subquery:4 Hosting operator id = 50 Hosting Expression = cr_returned_date_sk#48 IN dynamicpruning#5

Subquery:5 Hosting operator id = 63 Hosting Expression = ws_sold_date_sk#64 IN dynamicpruning#5

Subquery:6 Hosting operator id = 80 Hosting Expression = wr_returned_date_sk#78 IN dynamicpruning#5


